{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob     ## for reading files we use glob module\n",
    "import librosa as lr      ## special lib to read and manipulate audio files\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import json\n",
    "import time\n",
    "import io\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from  sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix \n",
    "##from sklearn.metrics import multiclass_roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import normalize, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = r'D:\\Nikita Old Laptop\\TH Koln\\RP_NEW'\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is New Volume\n",
      " Volume Serial Number is F2BE-10BF\n",
      "\n",
      " Directory of D:\\Nikita Old Laptop\\TH Koln\\RP_NEW\n",
      "\n",
      "31/10/2021  20:42    <DIR>          .\n",
      "31/10/2021  20:42    <DIR>          ..\n",
      "04/10/2021  18:05    <DIR>          ALL\n",
      "10/04/2021  12:53       495.705.834 ALL.zip\n",
      "17/08/2021  12:18    <DIR>          ALL2\n",
      "17/08/2021  12:19    <DIR>          ALL2 old\n",
      "31/10/2021  12:29       575.308.975 ALL2.zip\n",
      "17/08/2021  12:19    <DIR>          Chunks\n",
      "30/03/2021  12:49            31.372 Concat_OneHotEncoding_MFCCExtract.PNG\n",
      "05/10/2021  00:02               862 DL Links.txt\n",
      "17/08/2021  12:19    <DIR>          Dog Bark Wav files\n",
      "17/08/2021  12:19    <DIR>          Dog_Chunks_Revised\n",
      "02/05/2021  20:45               261 Dog_Species_Name.txt\n",
      "17/12/2020  12:36        36.704.150 dogfilescompressed.zip\n",
      "17/08/2021  12:19    <DIR>          DSP\n",
      "17/08/2021  12:19    <DIR>          dsplab\n",
      "31/10/2021  18:21    <DIR>          Files\n",
      "31/10/2021  18:49                 0 finalized_model.sav\n",
      "31/10/2021  21:37               755 flask.py\n",
      "17/08/2021  12:19    <DIR>          German_shephard\n",
      "17/08/2021  12:19    <DIR>          German_shephard New\n",
      "17/08/2021  12:20    <DIR>          GreatDaneVoice\n",
      "31/10/2021  20:40               764 htmllocal.html\n",
      "31/10/2021  19:44               784 index.html.txt\n",
      "27/04/2021  13:51             3.362 labels_train0_test1.txt\n",
      "22/03/2021  19:34           209.123 MFCC_To_Do_Dataset.PNG\n",
      "31/10/2021  19:58                 0 model.pkl\n",
      "06/05/2021  23:07           686.422 Multiclass ROC.png\n",
      "01/10/2021  17:21    <DIR>          my_dir\n",
      "31/10/2021  19:27    <DIR>          my_model\n",
      "31/10/2021  20:42        42.721.848 my_model.h5\n",
      "17/08/2021  12:20    <DIR>          New folder\n",
      "02/05/2021  20:45             4.216 new_labels_train0_test1.txt\n",
      "27/04/2021  13:50            17.601 new_rec_id_File_nake.txt\n",
      "02/05/2021  20:45            21.662 new_rec_id_File_name_Labels.txt\n",
      "17/08/2021  12:20    <DIR>          NewEditted\n",
      "02/05/2021  20:37    <DIR>          NewStart\n",
      "30/03/2021  12:45            89.810 One_Hot_Encoding.PNG\n",
      "01/10/2021  15:32    <DIR>          output\n",
      "31/03/2021  20:34            17.639 rec_id_File_nake.txt\n",
      "30/03/2021  16:25            15.693 rec_id_File_name.txt\n",
      "31/03/2021  20:33            17.049 rec_id_File_name_Labels.txt\n",
      "13/07/2021  16:41         2.500.065 RP Final paper of mine revised.docx\n",
      "04/07/2021  20:37         2.501.450 RP Final paper of mine.docx\n",
      "04/07/2021  20:38         2.876.685 rp.pdf\n",
      "02/07/2021  13:03         4.036.260 RP_Paper_Mine.docx\n",
      "17/08/2021  12:20    <DIR>          test\n",
      "17/08/2021  12:23    <DIR>          Test_data\n",
      "17/08/2021  12:23    <DIR>          thkdsp\n",
      "17/08/2021  12:24    <DIR>          ttt\n",
      "01/10/2021  14:35    <DIR>          untitled_project\n",
      "              26 File(s)  1.163.472.642 bytes\n",
      "              25 Dir(s)  14.978.396.160 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog_id</th>\n",
       "      <th>dog_code</th>\n",
       "      <th>dog_species_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BT</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BX</td>\n",
       "      <td>Boxer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BD</td>\n",
       "      <td>Bulldog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CS</td>\n",
       "      <td>AlaskanMalamute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DB</td>\n",
       "      <td>Doberman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>GS</td>\n",
       "      <td>German_shephard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>GR</td>\n",
       "      <td>Golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>GD</td>\n",
       "      <td>GreatDane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>LB</td>\n",
       "      <td>Labrador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>PB</td>\n",
       "      <td>Pitbull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>PM</td>\n",
       "      <td>Pomeranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>PD</td>\n",
       "      <td>Poodle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>RT</td>\n",
       "      <td>Rottweiler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dog_id dog_code  dog_species_name\n",
       "0        1       BT    Boston_Terrier\n",
       "1        2       BX             Boxer\n",
       "2        3       BD           Bulldog\n",
       "3        4       CS   AlaskanMalamute\n",
       "4        5       DB          Doberman\n",
       "5        6       GS   German_shephard\n",
       "6        7       GR  Golden_retriever\n",
       "7        8       GD         GreatDane\n",
       "8        9       LB          Labrador\n",
       "9       10       PB           Pitbull\n",
       "10      11       PM        Pomeranian\n",
       "11      12       PD            Poodle\n",
       "12      13       RT        Rottweiler"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_species_name = pd.read_csv('Dog_Species_Name.txt')\n",
    "dog_species_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>dogspecies</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Boston_Terrier0</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Boston_Terrier0C</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Boston_Terrier0C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Boston_Terrier0C2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Boston_Terrier1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>712</td>\n",
       "      <td>Rottweiler57</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>713</td>\n",
       "      <td>Rottweiler58</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>714</td>\n",
       "      <td>Rottweiler59</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>715</td>\n",
       "      <td>Rottweiler60</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>716</td>\n",
       "      <td>Rottweiler61</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>717 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dog_id           filename      dogspecies  labels\n",
       "0         0    Boston_Terrier0  Boston_Terrier       1\n",
       "1         1   Boston_Terrier0C  Boston_Terrier       1\n",
       "2         2  Boston_Terrier0C1  Boston_Terrier       1\n",
       "3         3  Boston_Terrier0C2  Boston_Terrier       1\n",
       "4         4    Boston_Terrier1  Boston_Terrier       1\n",
       "..      ...                ...             ...     ...\n",
       "712     712       Rottweiler57      Rottweiler      13\n",
       "713     713       Rottweiler58      Rottweiler      13\n",
       "714     714       Rottweiler59      Rottweiler      13\n",
       "715     715       Rottweiler60      Rottweiler      13\n",
       "716     716       Rottweiler61      Rottweiler      13\n",
       "\n",
       "[717 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = pd.read_csv('new_rec_id_File_name_Labels.txt')\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>713</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>715</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>716</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>717</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dog_id  label\n",
       "0        0    1.0\n",
       "1        1    1.0\n",
       "2        2    1.0\n",
       "3        3    1.0\n",
       "4        4    1.0\n",
       "..     ...    ...\n",
       "714    713    0.0\n",
       "715    714    0.0\n",
       "716    715    0.0\n",
       "717    716    0.0\n",
       "718    717    0.0\n",
       "\n",
       "[719 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('new_labels_train0_test1.txt')\n",
    "labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "*******************************Reading the audio files***********************************************\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = r'D:\\Nikita Old Laptop\\TH Koln\\RP_NEW\\ALL2'\n",
    "audio_files = glob(data_dir + '/*.wav')   #reading audio files\n",
    "len(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n"
     ]
    }
   ],
   "source": [
    "audio, sfreq = lr.load(audio_files[0])   ## reading the first audio file and create time array(timeline)\n",
    "## This returns an audio time series as a numpy array with a default sampling rate(sr) of 22KHZ\n",
    "x= librosa.load(audio_files[0], sr=None)  \n",
    "time = np.arange(0, len(audio)) / sfreq \n",
    "time\n",
    "print (sfreq)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "*****************************MFCC*************************************\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['MFCCS Extract'])\n",
    "counter=0\n",
    "for file in range(0,len(audio_files), 1):\n",
    "    audio, sfreq = lr.load(audio_files [file])\n",
    "    sampling_rate= np.array(sfreq)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=audio, sr=sampling_rate, n_mfcc=13),axis=0)\n",
    "    df.loc[counter]  = [mfccs]\n",
    "    counter = (counter + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCS Extract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-50.041462, -50.00325, -49.94745, -48.34558, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-46.790066, -44.80235, -43.05767, -41.74796, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-39.957363, -39.143734, -39.61368, -41.67441,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-55.828674, -55.828674, -55.828674, -55.82867...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-36.97554, -36.364017, -37.446835, -38.520287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-41.524574, -40.81351, -40.87403, -39.98979, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-40.070084, -39.02108, -39.519962, -39.05342,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-38.754574, -39.78123, -40.115776, -41.070683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-43.481377, -44.036358, -45.095116, -45.04360...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-32.485435, -33.935074, -34.60613, -33.777603...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       MFCCS Extract\n",
       "0  [-50.041462, -50.00325, -49.94745, -48.34558, ...\n",
       "1  [-46.790066, -44.80235, -43.05767, -41.74796, ...\n",
       "2  [-39.957363, -39.143734, -39.61368, -41.67441,...\n",
       "3  [-55.828674, -55.828674, -55.828674, -55.82867...\n",
       "4  [-36.97554, -36.364017, -37.446835, -38.520287...\n",
       "5  [-41.524574, -40.81351, -40.87403, -39.98979, ...\n",
       "6  [-40.070084, -39.02108, -39.519962, -39.05342,...\n",
       "7  [-38.754574, -39.78123, -40.115776, -41.070683...\n",
       "8  [-43.481377, -44.036358, -45.095116, -45.04360...\n",
       "9  [-32.485435, -33.935074, -34.60613, -33.777603..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([file_name, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>dogspecies</th>\n",
       "      <th>labels</th>\n",
       "      <th>dog_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Boston_Terrier0</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Boston_Terrier0C</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Boston_Terrier0C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Boston_Terrier0C2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Boston_Terrier1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dog_id           filename      dogspecies  labels dog_id  label\n",
       "0    0.0    Boston_Terrier0  Boston_Terrier     1.0      0    1.0\n",
       "1    1.0   Boston_Terrier0C  Boston_Terrier     1.0      1    1.0\n",
       "2    2.0  Boston_Terrier0C1  Boston_Terrier     1.0      2    1.0\n",
       "3    3.0  Boston_Terrier0C2  Boston_Terrier     1.0      3    1.0\n",
       "4    4.0    Boston_Terrier1  Boston_Terrier     1.0      4    1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>dogspecies</th>\n",
       "      <th>labels</th>\n",
       "      <th>dog_id</th>\n",
       "      <th>label</th>\n",
       "      <th>MFCCS Extract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Boston_Terrier0</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-50.041462, -50.00325, -49.94745, -48.34558, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Boston_Terrier0C</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-46.790066, -44.80235, -43.05767, -41.74796, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Boston_Terrier0C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-39.957363, -39.143734, -39.61368, -41.67441,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Boston_Terrier0C2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-55.828674, -55.828674, -55.828674, -55.82867...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Boston_Terrier1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-36.97554, -36.364017, -37.446835, -38.520287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Boston_Terrier1C</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-41.524574, -40.81351, -40.87403, -39.98979, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Boston_Terrier1C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-40.070084, -39.02108, -39.519962, -39.05342,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Boston_Terrier1C2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-38.754574, -39.78123, -40.115776, -41.070683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Boston_Terrier2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-43.481377, -44.036358, -45.095116, -45.04360...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Boston_Terrier2C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-32.485435, -33.935074, -34.60613, -33.777603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Boston_Terrier2C2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-44.908245, -44.909523, -43.673626, -42.00966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Boston_Terrier3</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-43.250713, -42.86821, -43.355637, -44.05754,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dog_id           filename      dogspecies  labels dog_id  label  \\\n",
       "0     0.0    Boston_Terrier0  Boston_Terrier     1.0      0    1.0   \n",
       "1     1.0   Boston_Terrier0C  Boston_Terrier     1.0      1    1.0   \n",
       "2     2.0  Boston_Terrier0C1  Boston_Terrier     1.0      2    1.0   \n",
       "3     3.0  Boston_Terrier0C2  Boston_Terrier     1.0      3    1.0   \n",
       "4     4.0    Boston_Terrier1  Boston_Terrier     1.0      4    1.0   \n",
       "5     5.0   Boston_Terrier1C  Boston_Terrier     1.0      5    1.0   \n",
       "6     6.0  Boston_Terrier1C1  Boston_Terrier     1.0      6    1.0   \n",
       "7     7.0  Boston_Terrier1C2  Boston_Terrier     1.0      7    1.0   \n",
       "8     8.0    Boston_Terrier2  Boston_Terrier     1.0      8    1.0   \n",
       "9     9.0  Boston_Terrier2C1  Boston_Terrier     1.0      9    1.0   \n",
       "10   10.0  Boston_Terrier2C2  Boston_Terrier     1.0     10    1.0   \n",
       "11   11.0    Boston_Terrier3  Boston_Terrier     1.0     11    1.0   \n",
       "\n",
       "                                        MFCCS Extract  \n",
       "0   [-50.041462, -50.00325, -49.94745, -48.34558, ...  \n",
       "1   [-46.790066, -44.80235, -43.05767, -41.74796, ...  \n",
       "2   [-39.957363, -39.143734, -39.61368, -41.67441,...  \n",
       "3   [-55.828674, -55.828674, -55.828674, -55.82867...  \n",
       "4   [-36.97554, -36.364017, -37.446835, -38.520287...  \n",
       "5   [-41.524574, -40.81351, -40.87403, -39.98979, ...  \n",
       "6   [-40.070084, -39.02108, -39.519962, -39.05342,...  \n",
       "7   [-38.754574, -39.78123, -40.115776, -41.070683...  \n",
       "8   [-43.481377, -44.036358, -45.095116, -45.04360...  \n",
       "9   [-32.485435, -33.935074, -34.60613, -33.777603...  \n",
       "10  [-44.908245, -44.909523, -43.673626, -42.00966...  \n",
       "11  [-43.250713, -42.86821, -43.355637, -44.05754,...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_extract = pd.concat([dataset,pd.DataFrame(df['MFCCS Extract'])],axis=1)\n",
    "dataset_extract.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>dogspecies</th>\n",
       "      <th>labels</th>\n",
       "      <th>dog_id</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Boston_Terrier0</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-50.041462</td>\n",
       "      <td>-50.003250</td>\n",
       "      <td>-49.947449</td>\n",
       "      <td>-48.345581</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.876003</td>\n",
       "      <td>-34.681778</td>\n",
       "      <td>-34.901638</td>\n",
       "      <td>-36.760662</td>\n",
       "      <td>-36.373482</td>\n",
       "      <td>-35.598087</td>\n",
       "      <td>-35.282864</td>\n",
       "      <td>-35.864342</td>\n",
       "      <td>-36.235023</td>\n",
       "      <td>-36.159672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Boston_Terrier0C</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-46.790066</td>\n",
       "      <td>-44.802349</td>\n",
       "      <td>-43.057671</td>\n",
       "      <td>-41.747959</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.861435</td>\n",
       "      <td>-44.290188</td>\n",
       "      <td>-45.591446</td>\n",
       "      <td>-45.919601</td>\n",
       "      <td>-46.195679</td>\n",
       "      <td>-45.785397</td>\n",
       "      <td>-44.901859</td>\n",
       "      <td>-40.933559</td>\n",
       "      <td>-38.330448</td>\n",
       "      <td>-36.514595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Boston_Terrier0C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-39.957363</td>\n",
       "      <td>-39.143734</td>\n",
       "      <td>-39.613682</td>\n",
       "      <td>-41.674412</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Boston_Terrier0C2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.216812</td>\n",
       "      <td>-46.294334</td>\n",
       "      <td>-45.568333</td>\n",
       "      <td>-44.612759</td>\n",
       "      <td>-45.091316</td>\n",
       "      <td>-45.151089</td>\n",
       "      <td>-45.824944</td>\n",
       "      <td>-47.071823</td>\n",
       "      <td>-46.526569</td>\n",
       "      <td>-47.299664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Boston_Terrier1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-36.975540</td>\n",
       "      <td>-36.364017</td>\n",
       "      <td>-37.446835</td>\n",
       "      <td>-38.520287</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.474495</td>\n",
       "      <td>-40.251915</td>\n",
       "      <td>-40.150742</td>\n",
       "      <td>-39.654861</td>\n",
       "      <td>-39.441658</td>\n",
       "      <td>-39.536167</td>\n",
       "      <td>-40.015804</td>\n",
       "      <td>-39.968559</td>\n",
       "      <td>-38.872219</td>\n",
       "      <td>-38.958836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Boston_Terrier1C</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-41.524574</td>\n",
       "      <td>-40.813511</td>\n",
       "      <td>-40.874031</td>\n",
       "      <td>-39.989792</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.721806</td>\n",
       "      <td>-46.435493</td>\n",
       "      <td>-46.584736</td>\n",
       "      <td>-44.396542</td>\n",
       "      <td>-43.096634</td>\n",
       "      <td>-42.374905</td>\n",
       "      <td>-42.015518</td>\n",
       "      <td>-42.980721</td>\n",
       "      <td>-42.186081</td>\n",
       "      <td>-42.945065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Boston_Terrier1C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-40.070084</td>\n",
       "      <td>-39.021080</td>\n",
       "      <td>-39.519962</td>\n",
       "      <td>-39.053421</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.051170</td>\n",
       "      <td>-45.229763</td>\n",
       "      <td>-41.536190</td>\n",
       "      <td>-38.046181</td>\n",
       "      <td>-26.480526</td>\n",
       "      <td>-23.850372</td>\n",
       "      <td>-24.239733</td>\n",
       "      <td>-22.892021</td>\n",
       "      <td>-20.148836</td>\n",
       "      <td>-20.589781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Boston_Terrier1C2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-38.754574</td>\n",
       "      <td>-39.781231</td>\n",
       "      <td>-40.115776</td>\n",
       "      <td>-41.070683</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.082256</td>\n",
       "      <td>-27.107552</td>\n",
       "      <td>-27.017307</td>\n",
       "      <td>-28.480314</td>\n",
       "      <td>-30.478981</td>\n",
       "      <td>-32.646400</td>\n",
       "      <td>-34.091080</td>\n",
       "      <td>-37.385872</td>\n",
       "      <td>-39.024628</td>\n",
       "      <td>-39.374153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Boston_Terrier2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-43.481377</td>\n",
       "      <td>-44.036358</td>\n",
       "      <td>-45.095116</td>\n",
       "      <td>-45.043606</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.859554</td>\n",
       "      <td>-34.877705</td>\n",
       "      <td>-30.882170</td>\n",
       "      <td>-31.321337</td>\n",
       "      <td>-31.946712</td>\n",
       "      <td>-30.527700</td>\n",
       "      <td>-30.834158</td>\n",
       "      <td>-32.819862</td>\n",
       "      <td>-35.397251</td>\n",
       "      <td>-37.645828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Boston_Terrier2C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-32.485435</td>\n",
       "      <td>-33.935074</td>\n",
       "      <td>-34.606129</td>\n",
       "      <td>-33.777603</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.382439</td>\n",
       "      <td>-42.230949</td>\n",
       "      <td>-42.732681</td>\n",
       "      <td>-42.326534</td>\n",
       "      <td>-41.908524</td>\n",
       "      <td>-43.051548</td>\n",
       "      <td>-42.462723</td>\n",
       "      <td>-41.691372</td>\n",
       "      <td>-40.862061</td>\n",
       "      <td>-40.842728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Boston_Terrier2C2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-44.908245</td>\n",
       "      <td>-44.909523</td>\n",
       "      <td>-43.673626</td>\n",
       "      <td>-42.009666</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.216404</td>\n",
       "      <td>-44.044724</td>\n",
       "      <td>-44.401981</td>\n",
       "      <td>-43.622566</td>\n",
       "      <td>-45.295261</td>\n",
       "      <td>-44.575779</td>\n",
       "      <td>-45.341072</td>\n",
       "      <td>-45.756954</td>\n",
       "      <td>-45.780056</td>\n",
       "      <td>-46.505245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Boston_Terrier3</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-43.250713</td>\n",
       "      <td>-42.868210</td>\n",
       "      <td>-43.355637</td>\n",
       "      <td>-44.057541</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.272575</td>\n",
       "      <td>-33.555836</td>\n",
       "      <td>-36.539196</td>\n",
       "      <td>-39.978874</td>\n",
       "      <td>-41.206924</td>\n",
       "      <td>-41.023399</td>\n",
       "      <td>-41.526386</td>\n",
       "      <td>-43.191910</td>\n",
       "      <td>-43.917362</td>\n",
       "      <td>-44.344883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>Boston_Terrier3C</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-47.251076</td>\n",
       "      <td>-47.383904</td>\n",
       "      <td>-46.844585</td>\n",
       "      <td>-45.625320</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.969780</td>\n",
       "      <td>-44.440472</td>\n",
       "      <td>-39.733910</td>\n",
       "      <td>-38.049416</td>\n",
       "      <td>-36.831387</td>\n",
       "      <td>-36.074665</td>\n",
       "      <td>-36.782303</td>\n",
       "      <td>-37.834633</td>\n",
       "      <td>-37.959641</td>\n",
       "      <td>-36.749096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Boston_Terrier3C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-44.766949</td>\n",
       "      <td>-41.244099</td>\n",
       "      <td>-41.028851</td>\n",
       "      <td>-41.660828</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.072018</td>\n",
       "      <td>-50.072018</td>\n",
       "      <td>-50.072018</td>\n",
       "      <td>-50.072018</td>\n",
       "      <td>-50.072018</td>\n",
       "      <td>-50.072018</td>\n",
       "      <td>-50.072018</td>\n",
       "      <td>-50.072018</td>\n",
       "      <td>-50.072018</td>\n",
       "      <td>-50.072018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Boston_Terrier4</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.228676</td>\n",
       "      <td>-34.688820</td>\n",
       "      <td>-37.442513</td>\n",
       "      <td>-39.493279</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.840797</td>\n",
       "      <td>-34.292000</td>\n",
       "      <td>-37.035080</td>\n",
       "      <td>-38.805618</td>\n",
       "      <td>-41.147095</td>\n",
       "      <td>-44.866863</td>\n",
       "      <td>-46.132668</td>\n",
       "      <td>-46.782600</td>\n",
       "      <td>-46.894985</td>\n",
       "      <td>-47.757774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Boston_Terrier4C</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-34.228676</td>\n",
       "      <td>-34.688820</td>\n",
       "      <td>-37.442513</td>\n",
       "      <td>-39.493279</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.840797</td>\n",
       "      <td>-34.292000</td>\n",
       "      <td>-37.035080</td>\n",
       "      <td>-38.805618</td>\n",
       "      <td>-41.147095</td>\n",
       "      <td>-44.866863</td>\n",
       "      <td>-46.132668</td>\n",
       "      <td>-46.782600</td>\n",
       "      <td>-46.894985</td>\n",
       "      <td>-47.757774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>Boston_Terrier4C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-43.250713</td>\n",
       "      <td>-42.868210</td>\n",
       "      <td>-43.355637</td>\n",
       "      <td>-44.057541</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.272575</td>\n",
       "      <td>-33.555836</td>\n",
       "      <td>-36.539196</td>\n",
       "      <td>-39.978874</td>\n",
       "      <td>-41.206924</td>\n",
       "      <td>-41.023399</td>\n",
       "      <td>-41.526386</td>\n",
       "      <td>-43.191910</td>\n",
       "      <td>-43.917362</td>\n",
       "      <td>-44.344883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>Boston_Terrier5</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.041462</td>\n",
       "      <td>-50.003250</td>\n",
       "      <td>-49.947449</td>\n",
       "      <td>-48.345581</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.876003</td>\n",
       "      <td>-34.681778</td>\n",
       "      <td>-34.901638</td>\n",
       "      <td>-36.760662</td>\n",
       "      <td>-36.373482</td>\n",
       "      <td>-35.598087</td>\n",
       "      <td>-35.282864</td>\n",
       "      <td>-35.864342</td>\n",
       "      <td>-36.235023</td>\n",
       "      <td>-36.159672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>Boston_Terrier5C</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.552986</td>\n",
       "      <td>-38.008217</td>\n",
       "      <td>-39.235893</td>\n",
       "      <td>-38.532036</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.086422</td>\n",
       "      <td>-43.127113</td>\n",
       "      <td>-42.072735</td>\n",
       "      <td>-41.912838</td>\n",
       "      <td>-43.293766</td>\n",
       "      <td>-43.203003</td>\n",
       "      <td>-43.260941</td>\n",
       "      <td>-43.960506</td>\n",
       "      <td>-41.690361</td>\n",
       "      <td>-41.427124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Boston_Terrier5C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-55.858864</td>\n",
       "      <td>-55.858864</td>\n",
       "      <td>-55.858864</td>\n",
       "      <td>-55.858864</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.759354</td>\n",
       "      <td>-33.277191</td>\n",
       "      <td>-36.485783</td>\n",
       "      <td>-38.734230</td>\n",
       "      <td>-40.927738</td>\n",
       "      <td>-34.489616</td>\n",
       "      <td>-28.915316</td>\n",
       "      <td>-28.987591</td>\n",
       "      <td>-30.138432</td>\n",
       "      <td>-26.203815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dog_id           filename      dogspecies  labels dog_id  label          0  \\\n",
       "0     0.0    Boston_Terrier0  Boston_Terrier     1.0      0    1.0 -50.041462   \n",
       "1     1.0   Boston_Terrier0C  Boston_Terrier     1.0      1    1.0 -46.790066   \n",
       "2     2.0  Boston_Terrier0C1  Boston_Terrier     1.0      2    1.0 -39.957363   \n",
       "3     3.0  Boston_Terrier0C2  Boston_Terrier     1.0      3    1.0 -55.828674   \n",
       "4     4.0    Boston_Terrier1  Boston_Terrier     1.0      4    1.0 -36.975540   \n",
       "5     5.0   Boston_Terrier1C  Boston_Terrier     1.0      5    1.0 -41.524574   \n",
       "6     6.0  Boston_Terrier1C1  Boston_Terrier     1.0      6    1.0 -40.070084   \n",
       "7     7.0  Boston_Terrier1C2  Boston_Terrier     1.0      7    1.0 -38.754574   \n",
       "8     8.0    Boston_Terrier2  Boston_Terrier     1.0      8    1.0 -43.481377   \n",
       "9     9.0  Boston_Terrier2C1  Boston_Terrier     1.0      9    1.0 -32.485435   \n",
       "10   10.0  Boston_Terrier2C2  Boston_Terrier     1.0     10    1.0 -44.908245   \n",
       "11   11.0    Boston_Terrier3  Boston_Terrier     1.0     11    1.0 -43.250713   \n",
       "12   12.0   Boston_Terrier3C  Boston_Terrier     1.0     12    1.0 -47.251076   \n",
       "13   13.0  Boston_Terrier3C1  Boston_Terrier     1.0     13    1.0 -44.766949   \n",
       "14   14.0    Boston_Terrier4  Boston_Terrier     1.0     14    1.0 -34.228676   \n",
       "15   15.0   Boston_Terrier4C  Boston_Terrier     1.0     15    1.0 -34.228676   \n",
       "16   16.0  Boston_Terrier4C1  Boston_Terrier     1.0     16    0.0 -43.250713   \n",
       "17   17.0    Boston_Terrier5  Boston_Terrier     1.0     17    0.0 -50.041462   \n",
       "18   18.0   Boston_Terrier5C  Boston_Terrier     1.0     18    0.0 -37.552986   \n",
       "19   19.0  Boston_Terrier5C1  Boston_Terrier     1.0     19    0.0 -55.858864   \n",
       "\n",
       "            1          2          3  ...        421        422        423  \\\n",
       "0  -50.003250 -49.947449 -48.345581  ... -32.876003 -34.681778 -34.901638   \n",
       "1  -44.802349 -43.057671 -41.747959  ... -43.861435 -44.290188 -45.591446   \n",
       "2  -39.143734 -39.613682 -41.674412  ... -49.985001 -49.985001 -49.985001   \n",
       "3  -55.828674 -55.828674 -55.828674  ... -47.216812 -46.294334 -45.568333   \n",
       "4  -36.364017 -37.446835 -38.520287  ... -39.474495 -40.251915 -40.150742   \n",
       "5  -40.813511 -40.874031 -39.989792  ... -46.721806 -46.435493 -46.584736   \n",
       "6  -39.021080 -39.519962 -39.053421  ... -44.051170 -45.229763 -41.536190   \n",
       "7  -39.781231 -40.115776 -41.070683  ... -27.082256 -27.107552 -27.017307   \n",
       "8  -44.036358 -45.095116 -45.043606  ... -36.859554 -34.877705 -30.882170   \n",
       "9  -33.935074 -34.606129 -33.777603  ... -42.382439 -42.230949 -42.732681   \n",
       "10 -44.909523 -43.673626 -42.009666  ... -43.216404 -44.044724 -44.401981   \n",
       "11 -42.868210 -43.355637 -44.057541  ... -32.272575 -33.555836 -36.539196   \n",
       "12 -47.383904 -46.844585 -45.625320  ... -43.969780 -44.440472 -39.733910   \n",
       "13 -41.244099 -41.028851 -41.660828  ... -50.072018 -50.072018 -50.072018   \n",
       "14 -34.688820 -37.442513 -39.493279  ... -31.840797 -34.292000 -37.035080   \n",
       "15 -34.688820 -37.442513 -39.493279  ... -31.840797 -34.292000 -37.035080   \n",
       "16 -42.868210 -43.355637 -44.057541  ... -32.272575 -33.555836 -36.539196   \n",
       "17 -50.003250 -49.947449 -48.345581  ... -32.876003 -34.681778 -34.901638   \n",
       "18 -38.008217 -39.235893 -38.532036  ... -43.086422 -43.127113 -42.072735   \n",
       "19 -55.858864 -55.858864 -55.858864  ... -36.759354 -33.277191 -36.485783   \n",
       "\n",
       "          424        425        426        427        428        429  \\\n",
       "0  -36.760662 -36.373482 -35.598087 -35.282864 -35.864342 -36.235023   \n",
       "1  -45.919601 -46.195679 -45.785397 -44.901859 -40.933559 -38.330448   \n",
       "2  -49.985001 -49.985001 -49.985001 -49.985001 -49.985001 -49.985001   \n",
       "3  -44.612759 -45.091316 -45.151089 -45.824944 -47.071823 -46.526569   \n",
       "4  -39.654861 -39.441658 -39.536167 -40.015804 -39.968559 -38.872219   \n",
       "5  -44.396542 -43.096634 -42.374905 -42.015518 -42.980721 -42.186081   \n",
       "6  -38.046181 -26.480526 -23.850372 -24.239733 -22.892021 -20.148836   \n",
       "7  -28.480314 -30.478981 -32.646400 -34.091080 -37.385872 -39.024628   \n",
       "8  -31.321337 -31.946712 -30.527700 -30.834158 -32.819862 -35.397251   \n",
       "9  -42.326534 -41.908524 -43.051548 -42.462723 -41.691372 -40.862061   \n",
       "10 -43.622566 -45.295261 -44.575779 -45.341072 -45.756954 -45.780056   \n",
       "11 -39.978874 -41.206924 -41.023399 -41.526386 -43.191910 -43.917362   \n",
       "12 -38.049416 -36.831387 -36.074665 -36.782303 -37.834633 -37.959641   \n",
       "13 -50.072018 -50.072018 -50.072018 -50.072018 -50.072018 -50.072018   \n",
       "14 -38.805618 -41.147095 -44.866863 -46.132668 -46.782600 -46.894985   \n",
       "15 -38.805618 -41.147095 -44.866863 -46.132668 -46.782600 -46.894985   \n",
       "16 -39.978874 -41.206924 -41.023399 -41.526386 -43.191910 -43.917362   \n",
       "17 -36.760662 -36.373482 -35.598087 -35.282864 -35.864342 -36.235023   \n",
       "18 -41.912838 -43.293766 -43.203003 -43.260941 -43.960506 -41.690361   \n",
       "19 -38.734230 -40.927738 -34.489616 -28.915316 -28.987591 -30.138432   \n",
       "\n",
       "          430  \n",
       "0  -36.159672  \n",
       "1  -36.514595  \n",
       "2  -49.985001  \n",
       "3  -47.299664  \n",
       "4  -38.958836  \n",
       "5  -42.945065  \n",
       "6  -20.589781  \n",
       "7  -39.374153  \n",
       "8  -37.645828  \n",
       "9  -40.842728  \n",
       "10 -46.505245  \n",
       "11 -44.344883  \n",
       "12 -36.749096  \n",
       "13 -50.072018  \n",
       "14 -47.757774  \n",
       "15 -47.757774  \n",
       "16 -44.344883  \n",
       "17 -36.159672  \n",
       "18 -41.427124  \n",
       "19 -26.203815  \n",
       "\n",
       "[20 rows x 437 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_extract = pd.concat([dataset,pd.DataFrame(df['MFCCS Extract'].values.tolist())],axis=1)\n",
    "dataset_extract.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>dogspecies</th>\n",
       "      <th>labels</th>\n",
       "      <th>dog_id</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Boston_Terrier0</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-50.041462</td>\n",
       "      <td>-50.003250</td>\n",
       "      <td>-49.947449</td>\n",
       "      <td>-48.345581</td>\n",
       "      <td>-47.775471</td>\n",
       "      <td>-47.037655</td>\n",
       "      <td>-47.173264</td>\n",
       "      <td>-47.701191</td>\n",
       "      <td>-49.982925</td>\n",
       "      <td>-48.504028</td>\n",
       "      <td>-47.447224</td>\n",
       "      <td>-48.465816</td>\n",
       "      <td>-49.632202</td>\n",
       "      <td>-48.666462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Boston_Terrier0C</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-46.790066</td>\n",
       "      <td>-44.802349</td>\n",
       "      <td>-43.057671</td>\n",
       "      <td>-41.747959</td>\n",
       "      <td>-41.896206</td>\n",
       "      <td>-44.005531</td>\n",
       "      <td>-42.820610</td>\n",
       "      <td>-43.163273</td>\n",
       "      <td>-43.077114</td>\n",
       "      <td>-43.233894</td>\n",
       "      <td>-43.896572</td>\n",
       "      <td>-44.711018</td>\n",
       "      <td>-42.195946</td>\n",
       "      <td>-31.426277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Boston_Terrier0C1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-39.957363</td>\n",
       "      <td>-39.143734</td>\n",
       "      <td>-39.613682</td>\n",
       "      <td>-41.674412</td>\n",
       "      <td>-40.498295</td>\n",
       "      <td>-39.722054</td>\n",
       "      <td>-38.753517</td>\n",
       "      <td>-38.400444</td>\n",
       "      <td>-38.729492</td>\n",
       "      <td>-38.416801</td>\n",
       "      <td>-39.125206</td>\n",
       "      <td>-38.837269</td>\n",
       "      <td>-37.967758</td>\n",
       "      <td>-37.834785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Boston_Terrier0C2</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Boston_Terrier1</td>\n",
       "      <td>Boston_Terrier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-36.975540</td>\n",
       "      <td>-36.364017</td>\n",
       "      <td>-37.446835</td>\n",
       "      <td>-38.520287</td>\n",
       "      <td>-38.777847</td>\n",
       "      <td>-39.352287</td>\n",
       "      <td>-40.239662</td>\n",
       "      <td>-40.569096</td>\n",
       "      <td>-40.738628</td>\n",
       "      <td>-41.662754</td>\n",
       "      <td>-41.178719</td>\n",
       "      <td>-41.141098</td>\n",
       "      <td>-41.432350</td>\n",
       "      <td>-41.018974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>714.0</td>\n",
       "      <td>Rottweiler59</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>13.0</td>\n",
       "      <td>713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-28.463297</td>\n",
       "      <td>-27.527332</td>\n",
       "      <td>-26.953836</td>\n",
       "      <td>-26.831566</td>\n",
       "      <td>-26.524406</td>\n",
       "      <td>-26.966545</td>\n",
       "      <td>-28.865671</td>\n",
       "      <td>-28.803789</td>\n",
       "      <td>-28.080811</td>\n",
       "      <td>-27.905174</td>\n",
       "      <td>-27.096754</td>\n",
       "      <td>-27.478951</td>\n",
       "      <td>-27.794039</td>\n",
       "      <td>-28.512486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>715.0</td>\n",
       "      <td>Rottweiler60</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>13.0</td>\n",
       "      <td>714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-30.286715</td>\n",
       "      <td>-29.165621</td>\n",
       "      <td>-28.156706</td>\n",
       "      <td>-29.097506</td>\n",
       "      <td>-28.868044</td>\n",
       "      <td>-28.214598</td>\n",
       "      <td>-29.192690</td>\n",
       "      <td>-28.001232</td>\n",
       "      <td>-27.167027</td>\n",
       "      <td>-29.099722</td>\n",
       "      <td>-30.399675</td>\n",
       "      <td>-28.865002</td>\n",
       "      <td>-28.852093</td>\n",
       "      <td>-29.121054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>716.0</td>\n",
       "      <td>Rottweiler61</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>13.0</td>\n",
       "      <td>715</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.511745</td>\n",
       "      <td>-25.712849</td>\n",
       "      <td>-23.687513</td>\n",
       "      <td>-21.413832</td>\n",
       "      <td>-22.780773</td>\n",
       "      <td>-22.799541</td>\n",
       "      <td>-24.381014</td>\n",
       "      <td>-23.372944</td>\n",
       "      <td>-23.810709</td>\n",
       "      <td>-23.893190</td>\n",
       "      <td>-24.130543</td>\n",
       "      <td>-24.127155</td>\n",
       "      <td>-24.301950</td>\n",
       "      <td>-23.473867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dog_id           filename      dogspecies  labels dog_id  label  \\\n",
       "0      0.0    Boston_Terrier0  Boston_Terrier     1.0      0    1.0   \n",
       "1      1.0   Boston_Terrier0C  Boston_Terrier     1.0      1    1.0   \n",
       "2      2.0  Boston_Terrier0C1  Boston_Terrier     1.0      2    1.0   \n",
       "3      3.0  Boston_Terrier0C2  Boston_Terrier     1.0      3    1.0   \n",
       "4      4.0    Boston_Terrier1  Boston_Terrier     1.0      4    1.0   \n",
       "..     ...                ...             ...     ...    ...    ...   \n",
       "714  714.0       Rottweiler59      Rottweiler    13.0    713    0.0   \n",
       "715  715.0       Rottweiler60      Rottweiler    13.0    714    0.0   \n",
       "716  716.0       Rottweiler61      Rottweiler    13.0    715    0.0   \n",
       "717    NaN                NaN             NaN     NaN    716    0.0   \n",
       "718    NaN                NaN             NaN     NaN    717    0.0   \n",
       "\n",
       "             0          1          2          3          4          5  \\\n",
       "0   -50.041462 -50.003250 -49.947449 -48.345581 -47.775471 -47.037655   \n",
       "1   -46.790066 -44.802349 -43.057671 -41.747959 -41.896206 -44.005531   \n",
       "2   -39.957363 -39.143734 -39.613682 -41.674412 -40.498295 -39.722054   \n",
       "3   -55.828674 -55.828674 -55.828674 -55.828674 -55.828674 -55.828674   \n",
       "4   -36.975540 -36.364017 -37.446835 -38.520287 -38.777847 -39.352287   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "714 -28.463297 -27.527332 -26.953836 -26.831566 -26.524406 -26.966545   \n",
       "715 -30.286715 -29.165621 -28.156706 -29.097506 -28.868044 -28.214598   \n",
       "716 -26.511745 -25.712849 -23.687513 -21.413832 -22.780773 -22.799541   \n",
       "717        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "718        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "             6          7          8          9         10         11  \\\n",
       "0   -47.173264 -47.701191 -49.982925 -48.504028 -47.447224 -48.465816   \n",
       "1   -42.820610 -43.163273 -43.077114 -43.233894 -43.896572 -44.711018   \n",
       "2   -38.753517 -38.400444 -38.729492 -38.416801 -39.125206 -38.837269   \n",
       "3   -55.828674 -55.828674 -55.828674 -55.828674 -55.828674 -55.828674   \n",
       "4   -40.239662 -40.569096 -40.738628 -41.662754 -41.178719 -41.141098   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "714 -28.865671 -28.803789 -28.080811 -27.905174 -27.096754 -27.478951   \n",
       "715 -29.192690 -28.001232 -27.167027 -29.099722 -30.399675 -28.865002   \n",
       "716 -24.381014 -23.372944 -23.810709 -23.893190 -24.130543 -24.127155   \n",
       "717        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "718        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "            12         13  \n",
       "0   -49.632202 -48.666462  \n",
       "1   -42.195946 -31.426277  \n",
       "2   -37.967758 -37.834785  \n",
       "3   -55.828674 -55.828674  \n",
       "4   -41.432350 -41.018974  \n",
       "..         ...        ...  \n",
       "714 -27.794039 -28.512486  \n",
       "715 -28.852093 -29.121054  \n",
       "716 -24.301950 -23.473867  \n",
       "717        NaN        NaN  \n",
       "718        NaN        NaN  \n",
       "\n",
       "[719 rows x 20 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_extract.iloc[:, : 20]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Drop all non numerical values and NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_extract = dataset_extract.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "711    13\n",
       "712    13\n",
       "714    13\n",
       "715    13\n",
       "716    13\n",
       "Name: labels, Length: 705, dtype: int32"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=dataset_extract.labels\n",
    "y=y.astype('int')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-50.041462</td>\n",
       "      <td>-50.003250</td>\n",
       "      <td>-49.947449</td>\n",
       "      <td>-48.345581</td>\n",
       "      <td>-47.775471</td>\n",
       "      <td>-47.037655</td>\n",
       "      <td>-47.173264</td>\n",
       "      <td>-47.701191</td>\n",
       "      <td>-49.982925</td>\n",
       "      <td>-48.504028</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.876003</td>\n",
       "      <td>-34.681778</td>\n",
       "      <td>-34.901638</td>\n",
       "      <td>-36.760662</td>\n",
       "      <td>-36.373482</td>\n",
       "      <td>-35.598087</td>\n",
       "      <td>-35.282864</td>\n",
       "      <td>-35.864342</td>\n",
       "      <td>-36.235023</td>\n",
       "      <td>-36.159672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-46.790066</td>\n",
       "      <td>-44.802349</td>\n",
       "      <td>-43.057671</td>\n",
       "      <td>-41.747959</td>\n",
       "      <td>-41.896206</td>\n",
       "      <td>-44.005531</td>\n",
       "      <td>-42.820610</td>\n",
       "      <td>-43.163273</td>\n",
       "      <td>-43.077114</td>\n",
       "      <td>-43.233894</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.861435</td>\n",
       "      <td>-44.290188</td>\n",
       "      <td>-45.591446</td>\n",
       "      <td>-45.919601</td>\n",
       "      <td>-46.195679</td>\n",
       "      <td>-45.785397</td>\n",
       "      <td>-44.901859</td>\n",
       "      <td>-40.933559</td>\n",
       "      <td>-38.330448</td>\n",
       "      <td>-36.514595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39.957363</td>\n",
       "      <td>-39.143734</td>\n",
       "      <td>-39.613682</td>\n",
       "      <td>-41.674412</td>\n",
       "      <td>-40.498295</td>\n",
       "      <td>-39.722054</td>\n",
       "      <td>-38.753517</td>\n",
       "      <td>-38.400444</td>\n",
       "      <td>-38.729492</td>\n",
       "      <td>-38.416801</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.216812</td>\n",
       "      <td>-46.294334</td>\n",
       "      <td>-45.568333</td>\n",
       "      <td>-44.612759</td>\n",
       "      <td>-45.091316</td>\n",
       "      <td>-45.151089</td>\n",
       "      <td>-45.824944</td>\n",
       "      <td>-47.071823</td>\n",
       "      <td>-46.526569</td>\n",
       "      <td>-47.299664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-36.975540</td>\n",
       "      <td>-36.364017</td>\n",
       "      <td>-37.446835</td>\n",
       "      <td>-38.520287</td>\n",
       "      <td>-38.777847</td>\n",
       "      <td>-39.352287</td>\n",
       "      <td>-40.239662</td>\n",
       "      <td>-40.569096</td>\n",
       "      <td>-40.738628</td>\n",
       "      <td>-41.662754</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.474495</td>\n",
       "      <td>-40.251915</td>\n",
       "      <td>-40.150742</td>\n",
       "      <td>-39.654861</td>\n",
       "      <td>-39.441658</td>\n",
       "      <td>-39.536167</td>\n",
       "      <td>-40.015804</td>\n",
       "      <td>-39.968559</td>\n",
       "      <td>-38.872219</td>\n",
       "      <td>-38.958836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0 -50.041462 -50.003250 -49.947449 -48.345581 -47.775471 -47.037655   \n",
       "1 -46.790066 -44.802349 -43.057671 -41.747959 -41.896206 -44.005531   \n",
       "2 -39.957363 -39.143734 -39.613682 -41.674412 -40.498295 -39.722054   \n",
       "3 -55.828674 -55.828674 -55.828674 -55.828674 -55.828674 -55.828674   \n",
       "4 -36.975540 -36.364017 -37.446835 -38.520287 -38.777847 -39.352287   \n",
       "\n",
       "         6          7          8          9    ...        421        422  \\\n",
       "0 -47.173264 -47.701191 -49.982925 -48.504028  ... -32.876003 -34.681778   \n",
       "1 -42.820610 -43.163273 -43.077114 -43.233894  ... -43.861435 -44.290188   \n",
       "2 -38.753517 -38.400444 -38.729492 -38.416801  ... -49.985001 -49.985001   \n",
       "3 -55.828674 -55.828674 -55.828674 -55.828674  ... -47.216812 -46.294334   \n",
       "4 -40.239662 -40.569096 -40.738628 -41.662754  ... -39.474495 -40.251915   \n",
       "\n",
       "         423        424        425        426        427        428  \\\n",
       "0 -34.901638 -36.760662 -36.373482 -35.598087 -35.282864 -35.864342   \n",
       "1 -45.591446 -45.919601 -46.195679 -45.785397 -44.901859 -40.933559   \n",
       "2 -49.985001 -49.985001 -49.985001 -49.985001 -49.985001 -49.985001   \n",
       "3 -45.568333 -44.612759 -45.091316 -45.151089 -45.824944 -47.071823   \n",
       "4 -40.150742 -39.654861 -39.441658 -39.536167 -40.015804 -39.968559   \n",
       "\n",
       "         429        430  \n",
       "0 -36.235023 -36.159672  \n",
       "1 -38.330448 -36.514595  \n",
       "2 -49.985001 -49.985001  \n",
       "3 -46.526569 -47.299664  \n",
       "4 -38.872219 -38.958836  \n",
       "\n",
       "[5 rows x 431 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dataset_extract.drop(['labels','dog_id','label','filename','dog_id','dogspecies'], axis=1)\n",
    "x.head() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Feature Scaling:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We know our dataset is not yet a scaled value, for instance the Boston_Ter has values in the range within 25 while Doberman has values in range within 80. To do so, we will use Scikit-Learn's StandardScaler class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-a8760818c81b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#sc = StandardScaler()\n",
    "#x_train = sc.fit_transform(x_train)\n",
    "#x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "******************Splitting the dataset into test and train********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size= 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-42.272320</td>\n",
       "      <td>-42.105095</td>\n",
       "      <td>-43.098701</td>\n",
       "      <td>-44.115906</td>\n",
       "      <td>-44.650925</td>\n",
       "      <td>-44.874748</td>\n",
       "      <td>-44.486488</td>\n",
       "      <td>-43.248405</td>\n",
       "      <td>-43.096951</td>\n",
       "      <td>-41.740807</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.742023</td>\n",
       "      <td>-45.832188</td>\n",
       "      <td>-44.413918</td>\n",
       "      <td>-43.393742</td>\n",
       "      <td>-44.070156</td>\n",
       "      <td>-45.458778</td>\n",
       "      <td>-44.939835</td>\n",
       "      <td>-43.502102</td>\n",
       "      <td>-44.809856</td>\n",
       "      <td>-44.214531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-36.069454</td>\n",
       "      <td>-36.069454</td>\n",
       "      <td>-36.069454</td>\n",
       "      <td>-36.069454</td>\n",
       "      <td>-36.069454</td>\n",
       "      <td>-36.069454</td>\n",
       "      <td>-36.069454</td>\n",
       "      <td>-36.069454</td>\n",
       "      <td>-36.069454</td>\n",
       "      <td>-36.069454</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.562180</td>\n",
       "      <td>-16.678587</td>\n",
       "      <td>-14.711318</td>\n",
       "      <td>-14.100725</td>\n",
       "      <td>-14.662766</td>\n",
       "      <td>-15.461031</td>\n",
       "      <td>-20.508993</td>\n",
       "      <td>-33.905003</td>\n",
       "      <td>-36.069454</td>\n",
       "      <td>-36.069454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-27.004137</td>\n",
       "      <td>-27.303862</td>\n",
       "      <td>-28.387459</td>\n",
       "      <td>-28.058664</td>\n",
       "      <td>-26.793324</td>\n",
       "      <td>-22.904348</td>\n",
       "      <td>-20.472979</td>\n",
       "      <td>-19.914295</td>\n",
       "      <td>-19.559786</td>\n",
       "      <td>-21.204027</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.205452</td>\n",
       "      <td>-22.658436</td>\n",
       "      <td>-22.557812</td>\n",
       "      <td>-21.874523</td>\n",
       "      <td>-23.078264</td>\n",
       "      <td>-22.899778</td>\n",
       "      <td>-23.293240</td>\n",
       "      <td>-23.957777</td>\n",
       "      <td>-24.234789</td>\n",
       "      <td>-24.018524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>-18.852114</td>\n",
       "      <td>-18.856640</td>\n",
       "      <td>-20.973360</td>\n",
       "      <td>-17.581261</td>\n",
       "      <td>-10.965231</td>\n",
       "      <td>-7.769562</td>\n",
       "      <td>-10.272451</td>\n",
       "      <td>-11.627513</td>\n",
       "      <td>-12.837032</td>\n",
       "      <td>-14.478555</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.118793</td>\n",
       "      <td>-22.061472</td>\n",
       "      <td>-21.259869</td>\n",
       "      <td>-21.376669</td>\n",
       "      <td>-20.268950</td>\n",
       "      <td>-19.884081</td>\n",
       "      <td>-21.078716</td>\n",
       "      <td>-23.414358</td>\n",
       "      <td>-24.466042</td>\n",
       "      <td>-24.915459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>-22.557688</td>\n",
       "      <td>-22.110014</td>\n",
       "      <td>-23.188692</td>\n",
       "      <td>-23.330736</td>\n",
       "      <td>-24.281189</td>\n",
       "      <td>-26.260874</td>\n",
       "      <td>-26.640324</td>\n",
       "      <td>-27.912727</td>\n",
       "      <td>-29.951536</td>\n",
       "      <td>-28.256948</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.509739</td>\n",
       "      <td>-27.143333</td>\n",
       "      <td>-26.276005</td>\n",
       "      <td>-25.375563</td>\n",
       "      <td>-27.428099</td>\n",
       "      <td>-22.808981</td>\n",
       "      <td>-19.086439</td>\n",
       "      <td>-18.387367</td>\n",
       "      <td>-20.060001</td>\n",
       "      <td>-22.193155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "24  -42.272320 -42.105095 -43.098701 -44.115906 -44.650925 -44.874748   \n",
       "157 -36.069454 -36.069454 -36.069454 -36.069454 -36.069454 -36.069454   \n",
       "214 -27.004137 -27.303862 -28.387459 -28.058664 -26.793324 -22.904348   \n",
       "265 -18.852114 -18.856640 -20.973360 -17.581261 -10.965231  -7.769562   \n",
       "432 -22.557688 -22.110014 -23.188692 -23.330736 -24.281189 -26.260874   \n",
       "\n",
       "           6          7          8          9    ...        421        422  \\\n",
       "24  -44.486488 -43.248405 -43.096951 -41.740807  ... -43.742023 -45.832188   \n",
       "157 -36.069454 -36.069454 -36.069454 -36.069454  ... -16.562180 -16.678587   \n",
       "214 -20.472979 -19.914295 -19.559786 -21.204027  ... -22.205452 -22.658436   \n",
       "265 -10.272451 -11.627513 -12.837032 -14.478555  ... -24.118793 -22.061472   \n",
       "432 -26.640324 -27.912727 -29.951536 -28.256948  ... -27.509739 -27.143333   \n",
       "\n",
       "           423        424        425        426        427        428  \\\n",
       "24  -44.413918 -43.393742 -44.070156 -45.458778 -44.939835 -43.502102   \n",
       "157 -14.711318 -14.100725 -14.662766 -15.461031 -20.508993 -33.905003   \n",
       "214 -22.557812 -21.874523 -23.078264 -22.899778 -23.293240 -23.957777   \n",
       "265 -21.259869 -21.376669 -20.268950 -19.884081 -21.078716 -23.414358   \n",
       "432 -26.276005 -25.375563 -27.428099 -22.808981 -19.086439 -18.387367   \n",
       "\n",
       "           429        430  \n",
       "24  -44.809856 -44.214531  \n",
       "157 -36.069454 -36.069454  \n",
       "214 -24.234789 -24.018524  \n",
       "265 -24.466042 -24.915459  \n",
       "432 -20.060001 -22.193155  \n",
       "\n",
       "[5 rows x 431 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 431)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>-8.079051</td>\n",
       "      <td>-12.741765</td>\n",
       "      <td>-25.956562</td>\n",
       "      <td>-28.356922</td>\n",
       "      <td>-30.420055</td>\n",
       "      <td>-28.966421</td>\n",
       "      <td>-24.851067</td>\n",
       "      <td>-24.089893</td>\n",
       "      <td>-21.585308</td>\n",
       "      <td>-20.550749</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.764336</td>\n",
       "      <td>-29.139885</td>\n",
       "      <td>-25.656834</td>\n",
       "      <td>-22.865536</td>\n",
       "      <td>-19.941277</td>\n",
       "      <td>-18.414726</td>\n",
       "      <td>-18.525921</td>\n",
       "      <td>-18.924618</td>\n",
       "      <td>-19.917616</td>\n",
       "      <td>-18.703056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-8.018672</td>\n",
       "      <td>-12.299545</td>\n",
       "      <td>-22.445728</td>\n",
       "      <td>-21.507324</td>\n",
       "      <td>-23.189615</td>\n",
       "      <td>-23.630627</td>\n",
       "      <td>-23.724072</td>\n",
       "      <td>-24.848400</td>\n",
       "      <td>-22.335423</td>\n",
       "      <td>-22.880848</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.506071</td>\n",
       "      <td>-27.613495</td>\n",
       "      <td>-26.474241</td>\n",
       "      <td>-27.600870</td>\n",
       "      <td>-28.238659</td>\n",
       "      <td>-28.473372</td>\n",
       "      <td>-29.238810</td>\n",
       "      <td>-28.128305</td>\n",
       "      <td>-27.381636</td>\n",
       "      <td>-29.574556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-29.747419</td>\n",
       "      <td>-28.982883</td>\n",
       "      <td>-30.019182</td>\n",
       "      <td>-30.545807</td>\n",
       "      <td>-30.024782</td>\n",
       "      <td>-29.332890</td>\n",
       "      <td>-28.776838</td>\n",
       "      <td>-29.233101</td>\n",
       "      <td>-29.083889</td>\n",
       "      <td>-26.738995</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.945711</td>\n",
       "      <td>-29.169842</td>\n",
       "      <td>-29.571079</td>\n",
       "      <td>-27.907269</td>\n",
       "      <td>-27.348621</td>\n",
       "      <td>-27.574284</td>\n",
       "      <td>-27.321217</td>\n",
       "      <td>-29.453539</td>\n",
       "      <td>-29.023045</td>\n",
       "      <td>-28.557934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-28.268442</td>\n",
       "      <td>-27.808079</td>\n",
       "      <td>-28.325125</td>\n",
       "      <td>-28.138573</td>\n",
       "      <td>-26.559053</td>\n",
       "      <td>-23.305866</td>\n",
       "      <td>-20.278412</td>\n",
       "      <td>-21.143715</td>\n",
       "      <td>-21.045082</td>\n",
       "      <td>-21.197266</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.694258</td>\n",
       "      <td>-22.452240</td>\n",
       "      <td>-22.901663</td>\n",
       "      <td>-23.555807</td>\n",
       "      <td>-22.511610</td>\n",
       "      <td>-21.637287</td>\n",
       "      <td>-23.507967</td>\n",
       "      <td>-23.138456</td>\n",
       "      <td>-23.476168</td>\n",
       "      <td>-23.360579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-24.912880</td>\n",
       "      <td>-26.114683</td>\n",
       "      <td>-28.986174</td>\n",
       "      <td>-29.086678</td>\n",
       "      <td>-29.231838</td>\n",
       "      <td>-27.737680</td>\n",
       "      <td>-25.160778</td>\n",
       "      <td>-25.987764</td>\n",
       "      <td>-27.655712</td>\n",
       "      <td>-29.863731</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.506567</td>\n",
       "      <td>-19.183250</td>\n",
       "      <td>-19.793425</td>\n",
       "      <td>-19.792067</td>\n",
       "      <td>-19.369108</td>\n",
       "      <td>-17.977880</td>\n",
       "      <td>-19.170700</td>\n",
       "      <td>-18.101131</td>\n",
       "      <td>-18.129948</td>\n",
       "      <td>-19.848202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "486  -8.079051 -12.741765 -25.956562 -28.356922 -30.420055 -28.966421   \n",
       "81   -8.018672 -12.299545 -22.445728 -21.507324 -23.189615 -23.630627   \n",
       "77  -29.747419 -28.982883 -30.019182 -30.545807 -30.024782 -29.332890   \n",
       "212 -28.268442 -27.808079 -28.325125 -28.138573 -26.559053 -23.305866   \n",
       "325 -24.912880 -26.114683 -28.986174 -29.086678 -29.231838 -27.737680   \n",
       "\n",
       "           6          7          8          9    ...        421        422  \\\n",
       "486 -24.851067 -24.089893 -21.585308 -20.550749  ... -30.764336 -29.139885   \n",
       "81  -23.724072 -24.848400 -22.335423 -22.880848  ... -29.506071 -27.613495   \n",
       "77  -28.776838 -29.233101 -29.083889 -26.738995  ... -26.945711 -29.169842   \n",
       "212 -20.278412 -21.143715 -21.045082 -21.197266  ... -21.694258 -22.452240   \n",
       "325 -25.160778 -25.987764 -27.655712 -29.863731  ... -18.506567 -19.183250   \n",
       "\n",
       "           423        424        425        426        427        428  \\\n",
       "486 -25.656834 -22.865536 -19.941277 -18.414726 -18.525921 -18.924618   \n",
       "81  -26.474241 -27.600870 -28.238659 -28.473372 -29.238810 -28.128305   \n",
       "77  -29.571079 -27.907269 -27.348621 -27.574284 -27.321217 -29.453539   \n",
       "212 -22.901663 -23.555807 -22.511610 -21.637287 -23.507967 -23.138456   \n",
       "325 -19.793425 -19.792067 -19.369108 -17.977880 -19.170700 -18.101131   \n",
       "\n",
       "           429        430  \n",
       "486 -19.917616 -18.703056  \n",
       "81  -27.381636 -29.574556  \n",
       "77  -29.023045 -28.557934  \n",
       "212 -23.476168 -23.360579  \n",
       "325 -18.129948 -19.848202  \n",
       "\n",
       "[5 rows x 431 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 431)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-50.041462</td>\n",
       "      <td>-50.003250</td>\n",
       "      <td>-49.947449</td>\n",
       "      <td>-48.345581</td>\n",
       "      <td>-47.775471</td>\n",
       "      <td>-47.037655</td>\n",
       "      <td>-47.173264</td>\n",
       "      <td>-47.701191</td>\n",
       "      <td>-49.982925</td>\n",
       "      <td>-48.504028</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.876003</td>\n",
       "      <td>-34.681778</td>\n",
       "      <td>-34.901638</td>\n",
       "      <td>-36.760662</td>\n",
       "      <td>-36.373482</td>\n",
       "      <td>-35.598087</td>\n",
       "      <td>-35.282864</td>\n",
       "      <td>-35.864342</td>\n",
       "      <td>-36.235023</td>\n",
       "      <td>-36.159672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-46.790066</td>\n",
       "      <td>-44.802349</td>\n",
       "      <td>-43.057671</td>\n",
       "      <td>-41.747959</td>\n",
       "      <td>-41.896206</td>\n",
       "      <td>-44.005531</td>\n",
       "      <td>-42.820610</td>\n",
       "      <td>-43.163273</td>\n",
       "      <td>-43.077114</td>\n",
       "      <td>-43.233894</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.861435</td>\n",
       "      <td>-44.290188</td>\n",
       "      <td>-45.591446</td>\n",
       "      <td>-45.919601</td>\n",
       "      <td>-46.195679</td>\n",
       "      <td>-45.785397</td>\n",
       "      <td>-44.901859</td>\n",
       "      <td>-40.933559</td>\n",
       "      <td>-38.330448</td>\n",
       "      <td>-36.514595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39.957363</td>\n",
       "      <td>-39.143734</td>\n",
       "      <td>-39.613682</td>\n",
       "      <td>-41.674412</td>\n",
       "      <td>-40.498295</td>\n",
       "      <td>-39.722054</td>\n",
       "      <td>-38.753517</td>\n",
       "      <td>-38.400444</td>\n",
       "      <td>-38.729492</td>\n",
       "      <td>-38.416801</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "      <td>-49.985001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>-55.828674</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.216812</td>\n",
       "      <td>-46.294334</td>\n",
       "      <td>-45.568333</td>\n",
       "      <td>-44.612759</td>\n",
       "      <td>-45.091316</td>\n",
       "      <td>-45.151089</td>\n",
       "      <td>-45.824944</td>\n",
       "      <td>-47.071823</td>\n",
       "      <td>-46.526569</td>\n",
       "      <td>-47.299664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-36.975540</td>\n",
       "      <td>-36.364017</td>\n",
       "      <td>-37.446835</td>\n",
       "      <td>-38.520287</td>\n",
       "      <td>-38.777847</td>\n",
       "      <td>-39.352287</td>\n",
       "      <td>-40.239662</td>\n",
       "      <td>-40.569096</td>\n",
       "      <td>-40.738628</td>\n",
       "      <td>-41.662754</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.474495</td>\n",
       "      <td>-40.251915</td>\n",
       "      <td>-40.150742</td>\n",
       "      <td>-39.654861</td>\n",
       "      <td>-39.441658</td>\n",
       "      <td>-39.536167</td>\n",
       "      <td>-40.015804</td>\n",
       "      <td>-39.968559</td>\n",
       "      <td>-38.872219</td>\n",
       "      <td>-38.958836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>-29.229496</td>\n",
       "      <td>-27.581001</td>\n",
       "      <td>-25.175753</td>\n",
       "      <td>-21.627085</td>\n",
       "      <td>-21.553873</td>\n",
       "      <td>-24.421684</td>\n",
       "      <td>-25.289314</td>\n",
       "      <td>-23.398417</td>\n",
       "      <td>-23.672058</td>\n",
       "      <td>-24.214111</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.542528</td>\n",
       "      <td>-28.603130</td>\n",
       "      <td>-27.143188</td>\n",
       "      <td>-27.827238</td>\n",
       "      <td>-28.075167</td>\n",
       "      <td>-27.699768</td>\n",
       "      <td>-26.472902</td>\n",
       "      <td>-26.178205</td>\n",
       "      <td>-28.638268</td>\n",
       "      <td>-28.620625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>-24.708096</td>\n",
       "      <td>-26.926058</td>\n",
       "      <td>-30.946774</td>\n",
       "      <td>-31.771751</td>\n",
       "      <td>-29.448639</td>\n",
       "      <td>-28.138908</td>\n",
       "      <td>-28.443796</td>\n",
       "      <td>-28.106884</td>\n",
       "      <td>-30.312002</td>\n",
       "      <td>-30.948975</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.660004</td>\n",
       "      <td>-21.485533</td>\n",
       "      <td>-20.763216</td>\n",
       "      <td>-21.566040</td>\n",
       "      <td>-24.913506</td>\n",
       "      <td>-25.927425</td>\n",
       "      <td>-23.345217</td>\n",
       "      <td>-23.191069</td>\n",
       "      <td>-24.927338</td>\n",
       "      <td>-17.632538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>-28.463297</td>\n",
       "      <td>-27.527332</td>\n",
       "      <td>-26.953836</td>\n",
       "      <td>-26.831566</td>\n",
       "      <td>-26.524406</td>\n",
       "      <td>-26.966545</td>\n",
       "      <td>-28.865671</td>\n",
       "      <td>-28.803789</td>\n",
       "      <td>-28.080811</td>\n",
       "      <td>-27.905174</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.241730</td>\n",
       "      <td>-26.322710</td>\n",
       "      <td>-28.327282</td>\n",
       "      <td>-28.759712</td>\n",
       "      <td>-28.848125</td>\n",
       "      <td>-28.688608</td>\n",
       "      <td>-28.051098</td>\n",
       "      <td>-28.172863</td>\n",
       "      <td>-27.710461</td>\n",
       "      <td>-28.391420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>-30.286715</td>\n",
       "      <td>-29.165621</td>\n",
       "      <td>-28.156706</td>\n",
       "      <td>-29.097506</td>\n",
       "      <td>-28.868044</td>\n",
       "      <td>-28.214598</td>\n",
       "      <td>-29.192690</td>\n",
       "      <td>-28.001232</td>\n",
       "      <td>-27.167027</td>\n",
       "      <td>-29.099722</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.704935</td>\n",
       "      <td>-28.824524</td>\n",
       "      <td>-25.135113</td>\n",
       "      <td>-24.822599</td>\n",
       "      <td>-26.514225</td>\n",
       "      <td>-27.450989</td>\n",
       "      <td>-25.880554</td>\n",
       "      <td>-25.621838</td>\n",
       "      <td>-24.817371</td>\n",
       "      <td>-25.416527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>-26.511745</td>\n",
       "      <td>-25.712849</td>\n",
       "      <td>-23.687513</td>\n",
       "      <td>-21.413832</td>\n",
       "      <td>-22.780773</td>\n",
       "      <td>-22.799541</td>\n",
       "      <td>-24.381014</td>\n",
       "      <td>-23.372944</td>\n",
       "      <td>-23.810709</td>\n",
       "      <td>-23.893190</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.906656</td>\n",
       "      <td>-24.228466</td>\n",
       "      <td>-23.992716</td>\n",
       "      <td>-22.840193</td>\n",
       "      <td>-23.814535</td>\n",
       "      <td>-23.789013</td>\n",
       "      <td>-25.097483</td>\n",
       "      <td>-26.327110</td>\n",
       "      <td>-23.136892</td>\n",
       "      <td>-17.680275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>705 rows × 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "0   -50.041462 -50.003250 -49.947449 -48.345581 -47.775471 -47.037655   \n",
       "1   -46.790066 -44.802349 -43.057671 -41.747959 -41.896206 -44.005531   \n",
       "2   -39.957363 -39.143734 -39.613682 -41.674412 -40.498295 -39.722054   \n",
       "3   -55.828674 -55.828674 -55.828674 -55.828674 -55.828674 -55.828674   \n",
       "4   -36.975540 -36.364017 -37.446835 -38.520287 -38.777847 -39.352287   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "711 -29.229496 -27.581001 -25.175753 -21.627085 -21.553873 -24.421684   \n",
       "712 -24.708096 -26.926058 -30.946774 -31.771751 -29.448639 -28.138908   \n",
       "714 -28.463297 -27.527332 -26.953836 -26.831566 -26.524406 -26.966545   \n",
       "715 -30.286715 -29.165621 -28.156706 -29.097506 -28.868044 -28.214598   \n",
       "716 -26.511745 -25.712849 -23.687513 -21.413832 -22.780773 -22.799541   \n",
       "\n",
       "           6          7          8          9    ...        421        422  \\\n",
       "0   -47.173264 -47.701191 -49.982925 -48.504028  ... -32.876003 -34.681778   \n",
       "1   -42.820610 -43.163273 -43.077114 -43.233894  ... -43.861435 -44.290188   \n",
       "2   -38.753517 -38.400444 -38.729492 -38.416801  ... -49.985001 -49.985001   \n",
       "3   -55.828674 -55.828674 -55.828674 -55.828674  ... -47.216812 -46.294334   \n",
       "4   -40.239662 -40.569096 -40.738628 -41.662754  ... -39.474495 -40.251915   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "711 -25.289314 -23.398417 -23.672058 -24.214111  ... -29.542528 -28.603130   \n",
       "712 -28.443796 -28.106884 -30.312002 -30.948975  ... -20.660004 -21.485533   \n",
       "714 -28.865671 -28.803789 -28.080811 -27.905174  ... -26.241730 -26.322710   \n",
       "715 -29.192690 -28.001232 -27.167027 -29.099722  ... -29.704935 -28.824524   \n",
       "716 -24.381014 -23.372944 -23.810709 -23.893190  ... -22.906656 -24.228466   \n",
       "\n",
       "           423        424        425        426        427        428  \\\n",
       "0   -34.901638 -36.760662 -36.373482 -35.598087 -35.282864 -35.864342   \n",
       "1   -45.591446 -45.919601 -46.195679 -45.785397 -44.901859 -40.933559   \n",
       "2   -49.985001 -49.985001 -49.985001 -49.985001 -49.985001 -49.985001   \n",
       "3   -45.568333 -44.612759 -45.091316 -45.151089 -45.824944 -47.071823   \n",
       "4   -40.150742 -39.654861 -39.441658 -39.536167 -40.015804 -39.968559   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "711 -27.143188 -27.827238 -28.075167 -27.699768 -26.472902 -26.178205   \n",
       "712 -20.763216 -21.566040 -24.913506 -25.927425 -23.345217 -23.191069   \n",
       "714 -28.327282 -28.759712 -28.848125 -28.688608 -28.051098 -28.172863   \n",
       "715 -25.135113 -24.822599 -26.514225 -27.450989 -25.880554 -25.621838   \n",
       "716 -23.992716 -22.840193 -23.814535 -23.789013 -25.097483 -26.327110   \n",
       "\n",
       "           429        430  \n",
       "0   -36.235023 -36.159672  \n",
       "1   -38.330448 -36.514595  \n",
       "2   -49.985001 -49.985001  \n",
       "3   -46.526569 -47.299664  \n",
       "4   -38.872219 -38.958836  \n",
       "..         ...        ...  \n",
       "711 -28.638268 -28.620625  \n",
       "712 -24.927338 -17.632538  \n",
       "714 -27.710461 -28.391420  \n",
       "715 -24.817371 -25.416527  \n",
       "716 -23.136892 -17.680275  \n",
       "\n",
       "[705 rows x 431 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x).fillna(0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**********************************Deep Learning*************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution1D,MaxPooling1D,Dropout,Flatten,Dense,BatchNormalization,Conv1D,Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'utils' from 'tensorflow.keras.utils' (C:\\Users\\Nikita Majumder\\anaconda3\\lib\\site-packages\\tensorflow\\keras\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-b1d4e85ba091>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#y_train = np_utils.to_categorical(y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#y_test = np_utils.to_categorical(y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#y_train = keras.utils.to_categorical(y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#y_test = keras.utils.to_categorical(y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'utils' from 'tensorflow.keras.utils' (C:\\Users\\Nikita Majumder\\anaconda3\\lib\\site-packages\\tensorflow\\keras\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import utils \n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)\n",
    "#y_train = keras.utils.to_categorical(y_train)\n",
    "#y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = tensorflow.keras.utils.to_categorical(y_train)\n",
    "#y_test = tensorflow.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 431, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*********************Model 1******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(x_train.shape[1],1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(14, activation='softmax'))\n",
    "optimizer = tensorflow.keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 429, 32)           128       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 429, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 427, 64)           6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 427, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 213, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 213, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13632)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1745024   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                1806      \n",
      "=================================================================\n",
      "Total params: 1,753,550\n",
      "Trainable params: 1,753,358\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Compile\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer='Adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 6.3050 - accuracy: 0.2429 - val_loss: 43.3508 - val_accuracy: 0.0213\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 3.1183 - accuracy: 0.4645 - val_loss: 17.7586 - val_accuracy: 0.1560\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 1.6010 - accuracy: 0.6525 - val_loss: 9.0114 - val_accuracy: 0.1418\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 1.1405 - accuracy: 0.7358 - val_loss: 9.3692 - val_accuracy: 0.0638\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.6986 - accuracy: 0.8014 - val_loss: 5.5642 - val_accuracy: 0.1348\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.5932 - accuracy: 0.8511 - val_loss: 7.1904 - val_accuracy: 0.2270\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.5227 - accuracy: 0.8865 - val_loss: 4.2894 - val_accuracy: 0.2199\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.5682 - accuracy: 0.8528 - val_loss: 3.8315 - val_accuracy: 0.2695\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.4170 - accuracy: 0.9043 - val_loss: 2.6148 - val_accuracy: 0.3759\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.3831 - accuracy: 0.8972 - val_loss: 2.9337 - val_accuracy: 0.3546\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2999 - accuracy: 0.8972 - val_loss: 3.2054 - val_accuracy: 0.4255\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.3086 - accuracy: 0.9149 - val_loss: 3.4463 - val_accuracy: 0.3972\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2730 - accuracy: 0.9273 - val_loss: 2.9159 - val_accuracy: 0.4610\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1989 - accuracy: 0.9238 - val_loss: 3.3605 - val_accuracy: 0.4539\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2595 - accuracy: 0.9326 - val_loss: 4.1723 - val_accuracy: 0.4326\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2474 - accuracy: 0.9344 - val_loss: 3.9523 - val_accuracy: 0.5177\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.4272 - accuracy: 0.9397 - val_loss: 3.5096 - val_accuracy: 0.5461\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2541 - accuracy: 0.9255 - val_loss: 3.5077 - val_accuracy: 0.5532\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1881 - accuracy: 0.9255 - val_loss: 4.5980 - val_accuracy: 0.4539\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.1552 - accuracy: 0.9539 - val_loss: 4.8018 - val_accuracy: 0.4965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29647c032b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train and Test The Model\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=20, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 96.99%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 49.65%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*******************************Model 2 change******************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tensorflow.keras.utils.to_categorical(y_train)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 431, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not document this\n",
    "\n",
    "#Define Model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(x_train.shape[1],1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(14, activation='softmax'))\n",
    "optimizer = tensorflow.keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29648e61ee0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=100, verbose=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4822694957256317\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(x_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**********************Final Deep Learning Algorithm**************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 431, 1024)         6144      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 431, 1024)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 431, 1024)         4096      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 431, 1024)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 215, 1024)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 215, 512)          2621952   \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 215, 512)          0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 215, 512)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 215, 512)          2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 107, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 107, 256)          655616    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 107, 256)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 107, 256)          1024      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 107, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 53, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 53, 128)           163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 53, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 53, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 53, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 26, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 26, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 26, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 26, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 26, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 13, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 13, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 13, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               41700     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 14)                1414      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 3,550,154\n",
      "Trainable params: 3,546,122\n",
      "Non-trainable params: 4,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_value = 0.2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(1024, 5, padding='same',input_shape=(x_train.shape[1],1)))  \n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(dropout_value))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(512, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_value))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(256, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(dropout_value))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(128, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_value))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(64, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_value))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(32, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_value))\n",
    "        \n",
    "model.add(Flatten()) \n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(14)) \n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "18/18 [==============================] - 25s 1s/step - loss: 2.1626 - accuracy: 0.3174 - val_loss: 36.3653 - val_accuracy: 0.0213\n",
      "Epoch 2/25\n",
      "18/18 [==============================] - 29s 2s/step - loss: 1.2574 - accuracy: 0.5550 - val_loss: 18.5467 - val_accuracy: 0.0213\n",
      "Epoch 3/25\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.9073 - accuracy: 0.6968 - val_loss: 9.5192 - val_accuracy: 0.0567\n",
      "Epoch 4/25\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.6285 - accuracy: 0.7784 - val_loss: 3.6743 - val_accuracy: 0.0993\n",
      "Epoch 5/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.5351 - accuracy: 0.8138 - val_loss: 3.4539 - val_accuracy: 0.0851\n",
      "Epoch 6/25\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.3392 - accuracy: 0.8759 - val_loss: 3.3364 - val_accuracy: 0.1915\n",
      "Epoch 7/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.3299 - accuracy: 0.8723 - val_loss: 2.4526 - val_accuracy: 0.4539\n",
      "Epoch 8/25\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.3293 - accuracy: 0.8794 - val_loss: 2.0722 - val_accuracy: 0.5035\n",
      "Epoch 9/25\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.2481 - accuracy: 0.9113 - val_loss: 2.0175 - val_accuracy: 0.4894\n",
      "Epoch 10/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.3041 - accuracy: 0.8759 - val_loss: 1.7889 - val_accuracy: 0.5106\n",
      "Epoch 11/25\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.2791 - accuracy: 0.8989 - val_loss: 2.9166 - val_accuracy: 0.4113\n",
      "Epoch 12/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.2195 - accuracy: 0.9238 - val_loss: 2.5814 - val_accuracy: 0.4681\n",
      "Epoch 13/25\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.2690 - accuracy: 0.9078 - val_loss: 2.2784 - val_accuracy: 0.4752\n",
      "Epoch 14/25\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.2761 - accuracy: 0.8954 - val_loss: 1.2705 - val_accuracy: 0.6312\n",
      "Epoch 15/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.2762 - accuracy: 0.8989 - val_loss: 1.0460 - val_accuracy: 0.5319\n",
      "Epoch 16/25\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.2135 - accuracy: 0.9184 - val_loss: 1.5393 - val_accuracy: 0.5248\n",
      "Epoch 17/25\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.1965 - accuracy: 0.9220 - val_loss: 1.2039 - val_accuracy: 0.6241\n",
      "Epoch 18/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.1825 - accuracy: 0.9238 - val_loss: 1.2946 - val_accuracy: 0.5532\n",
      "Epoch 19/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.1657 - accuracy: 0.9326 - val_loss: 1.3447 - val_accuracy: 0.6099\n",
      "Epoch 20/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.1427 - accuracy: 0.9344 - val_loss: 1.4959 - val_accuracy: 0.5745\n",
      "Epoch 21/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.1933 - accuracy: 0.9255 - val_loss: 1.8207 - val_accuracy: 0.4965\n",
      "Epoch 22/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.2009 - accuracy: 0.9149 - val_loss: 2.7288 - val_accuracy: 0.3972\n",
      "Epoch 23/25\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.1837 - accuracy: 0.9273 - val_loss: 2.0393 - val_accuracy: 0.4681\n",
      "Epoch 24/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.1537 - accuracy: 0.9362 - val_loss: 2.9638 - val_accuracy: 0.4043\n",
      "Epoch 25/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.1799 - accuracy: 0.9309 - val_loss: 2.9892 - val_accuracy: 0.4823\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'Adam',metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=32, epochs = 25, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "18/18 [==============================] - 26s 1s/step - loss: 2.3209 - accuracy: 0.2837 - val_loss: 33.4672 - val_accuracy: 0.0496\n",
      "Epoch 2/25\n",
      "18/18 [==============================] - 30s 2s/step - loss: 1.3656 - accuracy: 0.5426 - val_loss: 14.5200 - val_accuracy: 0.0496\n",
      "Epoch 3/25\n",
      "18/18 [==============================] - 28s 2s/step - loss: 0.9651 - accuracy: 0.6401 - val_loss: 5.1362 - val_accuracy: 0.1135\n",
      "Epoch 4/25\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.6159 - accuracy: 0.7961 - val_loss: 3.8982 - val_accuracy: 0.1064\n",
      "Epoch 5/25\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.4716 - accuracy: 0.8351 - val_loss: 3.2153 - val_accuracy: 0.1489\n",
      "Epoch 6/25\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.4751 - accuracy: 0.8475 - val_loss: 2.5306 - val_accuracy: 0.3050\n",
      "Epoch 7/25\n",
      "18/18 [==============================] - 29s 2s/step - loss: 0.5316 - accuracy: 0.8333 - val_loss: 2.0495 - val_accuracy: 0.5319\n",
      "Epoch 8/25\n",
      "18/18 [==============================] - 31s 2s/step - loss: 0.3584 - accuracy: 0.8794 - val_loss: 1.3440 - val_accuracy: 0.5887\n",
      "Epoch 9/25\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.2729 - accuracy: 0.9025 - val_loss: 2.6517 - val_accuracy: 0.5035\n",
      "Epoch 10/25\n",
      "18/18 [==============================] - 30s 2s/step - loss: 0.2487 - accuracy: 0.8918 - val_loss: 2.9695 - val_accuracy: 0.4468\n",
      "Epoch 11/25\n",
      "18/18 [==============================] - 32s 2s/step - loss: 0.3858 - accuracy: 0.8564 - val_loss: 2.3450 - val_accuracy: 0.4397\n",
      "Epoch 12/25\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.2240 - accuracy: 0.9078 - val_loss: 1.2739 - val_accuracy: 0.5674\n",
      "Epoch 13/25\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.1745 - accuracy: 0.9309 - val_loss: 1.0237 - val_accuracy: 0.6383\n",
      "Epoch 14/25\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1701 - accuracy: 0.9309 - val_loss: 1.9123 - val_accuracy: 0.3972\n",
      "Epoch 15/25\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.3064 - accuracy: 0.9060 - val_loss: 2.1730 - val_accuracy: 0.4610\n",
      "Epoch 16/25\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.2361 - accuracy: 0.9043 - val_loss: 2.2152 - val_accuracy: 0.4468\n",
      "Epoch 17/25\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1815 - accuracy: 0.9309 - val_loss: 1.0272 - val_accuracy: 0.6241\n",
      "Epoch 18/25\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.2167 - accuracy: 0.9202 - val_loss: 0.7907 - val_accuracy: 0.7730\n",
      "Epoch 19/25\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1639 - accuracy: 0.9309 - val_loss: 0.7464 - val_accuracy: 0.7660\n",
      "Epoch 20/25\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1741 - accuracy: 0.9238 - val_loss: 0.6072 - val_accuracy: 0.7589\n",
      "Epoch 21/25\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1915 - accuracy: 0.9326 - val_loss: 1.1639 - val_accuracy: 0.6170\n",
      "Epoch 22/25\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.2289 - accuracy: 0.9043 - val_loss: 1.7179 - val_accuracy: 0.5816\n",
      "Epoch 23/25\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.2041 - accuracy: 0.9291 - val_loss: 1.7473 - val_accuracy: 0.5248\n",
      "Epoch 24/25\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.1577 - accuracy: 0.9255 - val_loss: 1.4247 - val_accuracy: 0.4823\n",
      "Epoch 25/25\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.2053 - accuracy: 0.9220 - val_loss: 1.1920 - val_accuracy: 0.6170\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'Adam',metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=32, epochs = 25, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00        19\n",
      "           3       0.00      0.00      0.00        16\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.12      0.60      0.20        20\n",
      "           8       0.00      0.00      0.00        10\n",
      "           9       0.00      0.00      0.00         7\n",
      "          10       0.00      0.00      0.00         8\n",
      "          11       0.00      0.00      0.00         9\n",
      "          12       0.10      0.23      0.14        13\n",
      "          13       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.11       141\n",
      "   macro avg       0.02      0.06      0.03       141\n",
      "weighted avg       0.03      0.11      0.04       141\n",
      "\n",
      "Accuracy on Validation Set 0.10638297872340426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "def model_classification_report(x_test,y_test ):\n",
    "  pred_prob=model.predict(x_test)  # predict validation set and compare with actual class\n",
    "  pred=np.argmax(pred_prob,axis=-1)\n",
    "  print(classification_report(np.argmax(y_test,axis=1),pred))\n",
    "  print('Accuracy on Validation Set',accuracy_score(pred,np.argmax(y_test,axis=1)))\n",
    "\n",
    "model_classification_report(x_test,y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       1.00      0.37      0.54        19\n",
      "           3       1.00      0.06      0.12        16\n",
      "           4       0.43      0.43      0.43         7\n",
      "           5       1.00      0.80      0.89        10\n",
      "           6       0.88      1.00      0.93         7\n",
      "           7       0.95      0.90      0.92        20\n",
      "           8       0.60      0.90      0.72        10\n",
      "           9       0.70      1.00      0.82         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       0.36      0.44      0.40         9\n",
      "          12       0.68      1.00      0.81        13\n",
      "          13       0.43      1.00      0.60        12\n",
      "\n",
      "    accuracy                           0.69       141\n",
      "   macro avg       0.69      0.68      0.63       141\n",
      "weighted avg       0.78      0.69      0.65       141\n",
      "\n",
      "Accuracy on Validation Set 0.6879432624113475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "def model_classification_report(x_test,y_test ):\n",
    "  pred_prob=model.predict(x_test)  # predict validation set and compare with actual class\n",
    "  pred=np.argmax(pred_prob,axis=-1)\n",
    "  print(classification_report(np.argmax(y_test,axis=1),pred))\n",
    "  print('Accuracy on Validation Set',accuracy_score(pred,np.argmax(y_test,axis=1)))\n",
    "\n",
    "model_classification_report(x_test,y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "18/18 [==============================] - 43s 2s/step - loss: 0.3056 - accuracy: 0.8936 - val_loss: 1.2276 - val_accuracy: 0.7376\n",
      "Epoch 2/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.4564 - accuracy: 0.8457 - val_loss: 2.6200 - val_accuracy: 0.5319\n",
      "Epoch 3/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.3951 - accuracy: 0.8528 - val_loss: 3.8210 - val_accuracy: 0.4752\n",
      "Epoch 4/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.2781 - accuracy: 0.8883 - val_loss: 2.3714 - val_accuracy: 0.5390\n",
      "Epoch 5/80\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.2118 - accuracy: 0.9184 - val_loss: 2.3426 - val_accuracy: 0.4894\n",
      "Epoch 6/80\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.2110 - accuracy: 0.8936 - val_loss: 1.4456 - val_accuracy: 0.6099\n",
      "Epoch 7/80\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.2210 - accuracy: 0.9096 - val_loss: 1.1294 - val_accuracy: 0.6879\n",
      "Epoch 8/80\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.1853 - accuracy: 0.9326 - val_loss: 0.7253 - val_accuracy: 0.7801\n",
      "Epoch 9/80\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.2463 - accuracy: 0.9167 - val_loss: 0.9131 - val_accuracy: 0.7234\n",
      "Epoch 10/80\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.2205 - accuracy: 0.9060 - val_loss: 3.0364 - val_accuracy: 0.5319\n",
      "Epoch 11/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.2056 - accuracy: 0.9309 - val_loss: 1.3356 - val_accuracy: 0.7092\n",
      "Epoch 12/80\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.2006 - accuracy: 0.9362 - val_loss: 0.6673 - val_accuracy: 0.8085\n",
      "Epoch 13/80\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.1395 - accuracy: 0.9379 - val_loss: 1.2582 - val_accuracy: 0.6454\n",
      "Epoch 14/80\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.2136 - accuracy: 0.9113 - val_loss: 0.6482 - val_accuracy: 0.8085\n",
      "Epoch 15/80\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.2180 - accuracy: 0.9113 - val_loss: 0.9291 - val_accuracy: 0.7234\n",
      "Epoch 16/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1593 - accuracy: 0.9433 - val_loss: 1.3997 - val_accuracy: 0.7092\n",
      "Epoch 17/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1506 - accuracy: 0.9326 - val_loss: 2.1083 - val_accuracy: 0.6950\n",
      "Epoch 18/80\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1647 - accuracy: 0.9344 - val_loss: 2.3136 - val_accuracy: 0.5390\n",
      "Epoch 19/80\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.1474 - accuracy: 0.9397 - val_loss: 1.6927 - val_accuracy: 0.5177\n",
      "Epoch 20/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1375 - accuracy: 0.9415 - val_loss: 1.3200 - val_accuracy: 0.7092\n",
      "Epoch 21/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.2083 - accuracy: 0.9096 - val_loss: 1.4703 - val_accuracy: 0.7021\n",
      "Epoch 22/80\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1425 - accuracy: 0.9397 - val_loss: 3.2070 - val_accuracy: 0.3688\n",
      "Epoch 23/80\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1348 - accuracy: 0.9415 - val_loss: 1.9561 - val_accuracy: 0.6596\n",
      "Epoch 24/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0950 - accuracy: 0.9539 - val_loss: 2.3662 - val_accuracy: 0.5390\n",
      "Epoch 25/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1050 - accuracy: 0.9557 - val_loss: 3.6357 - val_accuracy: 0.3333\n",
      "Epoch 26/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1025 - accuracy: 0.9504 - val_loss: 1.0359 - val_accuracy: 0.6525\n",
      "Epoch 27/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1180 - accuracy: 0.9504 - val_loss: 4.3725 - val_accuracy: 0.4326\n",
      "Epoch 28/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.1169 - accuracy: 0.9486 - val_loss: 1.7550 - val_accuracy: 0.7021\n",
      "Epoch 29/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1221 - accuracy: 0.9574 - val_loss: 3.5267 - val_accuracy: 0.3121\n",
      "Epoch 30/80\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1065 - accuracy: 0.9504 - val_loss: 4.9438 - val_accuracy: 0.2128\n",
      "Epoch 31/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1008 - accuracy: 0.9592 - val_loss: 6.2653 - val_accuracy: 0.2057\n",
      "Epoch 32/80\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0911 - accuracy: 0.9521 - val_loss: 9.3795 - val_accuracy: 0.1631\n",
      "Epoch 33/80\n",
      "18/18 [==============================] - 33s 2s/step - loss: 0.0812 - accuracy: 0.9628 - val_loss: 2.0023 - val_accuracy: 0.5177\n",
      "Epoch 34/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0960 - accuracy: 0.9574 - val_loss: 1.9441 - val_accuracy: 0.4539\n",
      "Epoch 35/80\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0869 - accuracy: 0.9628 - val_loss: 2.3760 - val_accuracy: 0.3333\n",
      "Epoch 36/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1210 - accuracy: 0.9504 - val_loss: 7.8940 - val_accuracy: 0.1915\n",
      "Epoch 37/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0957 - accuracy: 0.9557 - val_loss: 5.0287 - val_accuracy: 0.4043\n",
      "Epoch 38/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1705 - accuracy: 0.9326 - val_loss: 2.6051 - val_accuracy: 0.6525\n",
      "Epoch 39/80\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.1425 - accuracy: 0.9344 - val_loss: 2.6541 - val_accuracy: 0.6596\n",
      "Epoch 40/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.1461 - accuracy: 0.9468 - val_loss: 4.8970 - val_accuracy: 0.3759\n",
      "Epoch 41/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.1085 - accuracy: 0.9521 - val_loss: 2.6532 - val_accuracy: 0.5390\n",
      "Epoch 42/80\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1270 - accuracy: 0.9397 - val_loss: 2.6108 - val_accuracy: 0.5248\n",
      "Epoch 43/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.1973 - accuracy: 0.9273 - val_loss: 5.1723 - val_accuracy: 0.3759\n",
      "Epoch 44/80\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.1846 - accuracy: 0.9220 - val_loss: 5.6723 - val_accuracy: 0.3404\n",
      "Epoch 45/80\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.1666 - accuracy: 0.9291 - val_loss: 8.9004 - val_accuracy: 0.2411\n",
      "Epoch 46/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1287 - accuracy: 0.9344 - val_loss: 9.0767 - val_accuracy: 0.2411\n",
      "Epoch 47/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0873 - accuracy: 0.9610 - val_loss: 7.1267 - val_accuracy: 0.2199\n",
      "Epoch 48/80\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0835 - accuracy: 0.9628 - val_loss: 3.8719 - val_accuracy: 0.3901\n",
      "Epoch 49/80\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.1012 - accuracy: 0.9521 - val_loss: 4.7474 - val_accuracy: 0.4752\n",
      "Epoch 50/80\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0942 - accuracy: 0.9628 - val_loss: 4.0264 - val_accuracy: 0.5390\n",
      "Epoch 51/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0767 - accuracy: 0.9628 - val_loss: 3.4244 - val_accuracy: 0.4894\n",
      "Epoch 52/80\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0729 - accuracy: 0.9663 - val_loss: 5.4166 - val_accuracy: 0.3617\n",
      "Epoch 53/80\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0808 - accuracy: 0.9592 - val_loss: 2.0003 - val_accuracy: 0.6525\n",
      "Epoch 54/80\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0778 - accuracy: 0.9699 - val_loss: 3.9493 - val_accuracy: 0.4043\n",
      "Epoch 55/80\n",
      "18/18 [==============================] - 44s 2s/step - loss: 0.0854 - accuracy: 0.9645 - val_loss: 6.6822 - val_accuracy: 0.2482\n",
      "Epoch 56/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0887 - accuracy: 0.9574 - val_loss: 6.8511 - val_accuracy: 0.4823\n",
      "Epoch 57/80\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0604 - accuracy: 0.9663 - val_loss: 2.6811 - val_accuracy: 0.5532\n",
      "Epoch 58/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0668 - accuracy: 0.9663 - val_loss: 0.9693 - val_accuracy: 0.7021\n",
      "Epoch 59/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0734 - accuracy: 0.9663 - val_loss: 3.6690 - val_accuracy: 0.4965\n",
      "Epoch 60/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0869 - accuracy: 0.9592 - val_loss: 2.0907 - val_accuracy: 0.6596\n",
      "Epoch 61/80\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0654 - accuracy: 0.9628 - val_loss: 3.4756 - val_accuracy: 0.4823\n",
      "Epoch 62/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0881 - accuracy: 0.9592 - val_loss: 3.9782 - val_accuracy: 0.3759\n",
      "Epoch 63/80\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.0546 - accuracy: 0.9699 - val_loss: 1.8241 - val_accuracy: 0.5106\n",
      "Epoch 64/80\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0623 - accuracy: 0.9645 - val_loss: 3.7736 - val_accuracy: 0.4255\n",
      "Epoch 65/80\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0684 - accuracy: 0.9699 - val_loss: 1.5833 - val_accuracy: 0.5887\n",
      "Epoch 66/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0689 - accuracy: 0.9663 - val_loss: 2.6214 - val_accuracy: 0.4681\n",
      "Epoch 67/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0650 - accuracy: 0.9699 - val_loss: 6.2801 - val_accuracy: 0.3121\n",
      "Epoch 68/80\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0887 - accuracy: 0.9610 - val_loss: 10.0861 - val_accuracy: 0.2766\n",
      "Epoch 69/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0731 - accuracy: 0.9752 - val_loss: 6.0010 - val_accuracy: 0.3121\n",
      "Epoch 70/80\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0752 - accuracy: 0.9663 - val_loss: 10.8474 - val_accuracy: 0.1844\n",
      "Epoch 71/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0619 - accuracy: 0.9663 - val_loss: 7.7793 - val_accuracy: 0.2908\n",
      "Epoch 72/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0682 - accuracy: 0.9681 - val_loss: 12.1850 - val_accuracy: 0.1418\n",
      "Epoch 73/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0729 - accuracy: 0.9699 - val_loss: 9.1246 - val_accuracy: 0.1560\n",
      "Epoch 74/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0753 - accuracy: 0.9663 - val_loss: 6.5831 - val_accuracy: 0.4326\n",
      "Epoch 75/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0656 - accuracy: 0.9663 - val_loss: 6.8185 - val_accuracy: 0.2979\n",
      "Epoch 76/80\n",
      "18/18 [==============================] - 39s 2s/step - loss: 0.0929 - accuracy: 0.9699 - val_loss: 4.6928 - val_accuracy: 0.4255\n",
      "Epoch 77/80\n",
      "18/18 [==============================] - 31s 2s/step - loss: 0.0552 - accuracy: 0.9787 - val_loss: 6.4806 - val_accuracy: 0.3759\n",
      "Epoch 78/80\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.0582 - accuracy: 0.9716 - val_loss: 7.6899 - val_accuracy: 0.3972\n",
      "Epoch 79/80\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.0650 - accuracy: 0.9663 - val_loss: 1.3172 - val_accuracy: 0.6596\n",
      "Epoch 80/80\n",
      "18/18 [==============================] - 71s 4s/step - loss: 0.0662 - accuracy: 0.9716 - val_loss: 4.5018 - val_accuracy: 0.4823\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'Adam',metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=80, epochs = 25, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       1.00      0.21      0.35        19\n",
      "           3       0.00      0.00      0.00        16\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.67      0.60      0.63        10\n",
      "           6       0.24      1.00      0.39         7\n",
      "           7       0.67      0.80      0.73        20\n",
      "           8       0.59      1.00      0.74        10\n",
      "           9       0.17      0.86      0.29         7\n",
      "          10       1.00      0.88      0.93         8\n",
      "          11       0.00      0.00      0.00         9\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.48       141\n",
      "   macro avg       0.40      0.49      0.39       141\n",
      "weighted avg       0.47      0.48      0.42       141\n",
      "\n",
      "Accuracy on Validation Set 0.48226950354609927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "def model_classification_report(x_test,y_test ):\n",
    "  pred_prob=model.predict(x_test)  # predict validation set and compare with actual class\n",
    "  pred=np.argmax(pred_prob,axis=-1)\n",
    "  print(classification_report(np.argmax(y_test,axis=1),pred))\n",
    "  print('Accuracy on Validation Set',accuracy_score(pred,np.argmax(y_test,axis=1)))\n",
    "\n",
    "model_classification_report(x_test,y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.4018 - accuracy: 0.8652 - val_loss: 9.7200 - val_accuracy: 0.1064\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.1912 - accuracy: 0.9238 - val_loss: 5.1337 - val_accuracy: 0.3546\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.2110 - accuracy: 0.9149 - val_loss: 1.7441 - val_accuracy: 0.5461\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1399 - accuracy: 0.9415 - val_loss: 0.8230 - val_accuracy: 0.7092\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.1088 - accuracy: 0.9574 - val_loss: 0.8286 - val_accuracy: 0.6667\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1326 - accuracy: 0.9486 - val_loss: 1.4097 - val_accuracy: 0.5390\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1765 - accuracy: 0.9291 - val_loss: 1.2630 - val_accuracy: 0.5887\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1519 - accuracy: 0.9468 - val_loss: 0.6593 - val_accuracy: 0.7730\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1340 - accuracy: 0.9486 - val_loss: 1.1544 - val_accuracy: 0.6454\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1287 - accuracy: 0.9433 - val_loss: 1.7060 - val_accuracy: 0.5248\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1119 - accuracy: 0.9379 - val_loss: 0.8597 - val_accuracy: 0.7021\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1223 - accuracy: 0.9504 - val_loss: 0.6609 - val_accuracy: 0.7943\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1655 - accuracy: 0.9379 - val_loss: 0.6690 - val_accuracy: 0.8014\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.2402 - accuracy: 0.9149 - val_loss: 4.0949 - val_accuracy: 0.3830\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.3583 - accuracy: 0.8830 - val_loss: 19.9101 - val_accuracy: 0.0922\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1591 - accuracy: 0.9362 - val_loss: 7.7539 - val_accuracy: 0.2411\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1894 - accuracy: 0.9379 - val_loss: 5.6427 - val_accuracy: 0.2979\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1467 - accuracy: 0.9379 - val_loss: 2.3197 - val_accuracy: 0.4894\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1567 - accuracy: 0.9397 - val_loss: 2.5092 - val_accuracy: 0.4610\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1332 - accuracy: 0.9450 - val_loss: 2.9834 - val_accuracy: 0.4681\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.1103 - accuracy: 0.9486 - val_loss: 5.4786 - val_accuracy: 0.4113\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.1166 - accuracy: 0.9521 - val_loss: 2.2315 - val_accuracy: 0.4255\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.0860 - accuracy: 0.9628 - val_loss: 1.9395 - val_accuracy: 0.5106\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0942 - accuracy: 0.9521 - val_loss: 0.9342 - val_accuracy: 0.7021\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0872 - accuracy: 0.9557 - val_loss: 0.6892 - val_accuracy: 0.7163\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0998 - accuracy: 0.9610 - val_loss: 0.4971 - val_accuracy: 0.8298\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.0839 - accuracy: 0.9539 - val_loss: 0.6093 - val_accuracy: 0.7943\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.0826 - accuracy: 0.9557 - val_loss: 0.8382 - val_accuracy: 0.7872\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.0819 - accuracy: 0.9628 - val_loss: 0.6792 - val_accuracy: 0.7589\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1029 - accuracy: 0.9468 - val_loss: 0.4679 - val_accuracy: 0.8298\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.1083 - accuracy: 0.9450 - val_loss: 0.5584 - val_accuracy: 0.8014\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1007 - accuracy: 0.9539 - val_loss: 3.4566 - val_accuracy: 0.4681\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1020 - accuracy: 0.9539 - val_loss: 3.5332 - val_accuracy: 0.3546\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0902 - accuracy: 0.9574 - val_loss: 5.3889 - val_accuracy: 0.3121\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0925 - accuracy: 0.9557 - val_loss: 3.4598 - val_accuracy: 0.3688\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0815 - accuracy: 0.9681 - val_loss: 5.1970 - val_accuracy: 0.3546\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0914 - accuracy: 0.9574 - val_loss: 6.3493 - val_accuracy: 0.2979\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1323 - accuracy: 0.9504 - val_loss: 6.1908 - val_accuracy: 0.2766\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0949 - accuracy: 0.9592 - val_loss: 6.5151 - val_accuracy: 0.2624\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0976 - accuracy: 0.9610 - val_loss: 6.2521 - val_accuracy: 0.2766\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 36s 2s/step - loss: 0.0875 - accuracy: 0.9592 - val_loss: 6.4167 - val_accuracy: 0.2766\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0828 - accuracy: 0.9610 - val_loss: 7.1397 - val_accuracy: 0.2979\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0705 - accuracy: 0.9645 - val_loss: 3.4702 - val_accuracy: 0.4468\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 38s 2s/step - loss: 0.0724 - accuracy: 0.9610 - val_loss: 5.8650 - val_accuracy: 0.3617\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0821 - accuracy: 0.9663 - val_loss: 0.5688 - val_accuracy: 0.8085\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0773 - accuracy: 0.9610 - val_loss: 2.2451 - val_accuracy: 0.5816\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0741 - accuracy: 0.9645 - val_loss: 1.2785 - val_accuracy: 0.6312\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0956 - accuracy: 0.9574 - val_loss: 2.5050 - val_accuracy: 0.4894\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.1129 - accuracy: 0.9521 - val_loss: 1.3689 - val_accuracy: 0.7021\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.0799 - accuracy: 0.9645 - val_loss: 1.2276 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'Adam',metrics=['accuracy'])\n",
    "model_history=model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs = 50, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.89      0.42      0.57        19\n",
      "           3       0.14      0.06      0.09        16\n",
      "           4       0.38      0.43      0.40         7\n",
      "           5       1.00      0.80      0.89        10\n",
      "           6       0.88      1.00      0.93         7\n",
      "           7       1.00      1.00      1.00        20\n",
      "           8       0.83      1.00      0.91        10\n",
      "           9       0.78      1.00      0.88         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       0.75      0.33      0.46         9\n",
      "          12       0.44      0.54      0.48        13\n",
      "          13       0.38      1.00      0.55        12\n",
      "\n",
      "    accuracy                           0.67       141\n",
      "   macro avg       0.65      0.66      0.63       141\n",
      "weighted avg       0.69      0.67      0.64       141\n",
      "\n",
      "Accuracy on Validation Set 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "def model_classification_report(x_test,y_test ):\n",
    "  pred_prob=model.predict(x_test)  # predict validation set and compare with actual class\n",
    "  pred=np.argmax(pred_prob,axis=-1)\n",
    "  print(classification_report(np.argmax(y_test,axis=1),pred))\n",
    "  print('Accuracy on Validation Set',accuracy_score(pred,np.argmax(y_test,axis=1)))\n",
    "\n",
    "model_classification_report(x_test,y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 431, 1024)         6144      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 431, 1024)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 431, 1024)         4096      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 431, 1024)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 215, 1024)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 215, 512)          2621952   \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 215, 512)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 215, 512)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 215, 512)          2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 107, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 107, 256)          655616    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 107, 256)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 107, 256)          1024      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 107, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 53, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 53, 128)           163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 53, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 53, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 53, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 26, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 26, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 26, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 26, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 26, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 13, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 13, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 13, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               41700     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 14)                1414      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 3,550,154\n",
      "Trainable params: 3,546,122\n",
      "Non-trainable params: 4,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_value = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(1024, 5, padding='same',input_shape=(x_train.shape[1],1)))  \n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(dropout_value))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(512, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_value))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(256, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(dropout_value))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(128, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_value))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(64, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_value))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "\n",
    "model.add(Conv1D(32, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_value))\n",
    "        \n",
    "model.add(Flatten()) \n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(14)) \n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 23s 1s/step - loss: 2.2254 - accuracy: 0.3121 - val_loss: 10.8738 - val_accuracy: 0.1348\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 26s 1s/step - loss: 1.2259 - accuracy: 0.6152 - val_loss: 8.5286 - val_accuracy: 0.1489\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.7690 - accuracy: 0.7216 - val_loss: 5.1149 - val_accuracy: 0.1418\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.6167 - accuracy: 0.7660 - val_loss: 3.5396 - val_accuracy: 0.1773\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.5402 - accuracy: 0.8209 - val_loss: 3.0564 - val_accuracy: 0.1277\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.4995 - accuracy: 0.8209 - val_loss: 2.4058 - val_accuracy: 0.2624\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.3421 - accuracy: 0.8617 - val_loss: 2.6256 - val_accuracy: 0.2270\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.2549 - accuracy: 0.8972 - val_loss: 2.2653 - val_accuracy: 0.4397\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.2730 - accuracy: 0.8812 - val_loss: 2.0187 - val_accuracy: 0.5106\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.2915 - accuracy: 0.8848 - val_loss: 1.3967 - val_accuracy: 0.5106\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.2508 - accuracy: 0.8883 - val_loss: 2.3876 - val_accuracy: 0.3617\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.2590 - accuracy: 0.8883 - val_loss: 1.7149 - val_accuracy: 0.4752\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.3174 - accuracy: 0.8759 - val_loss: 2.3033 - val_accuracy: 0.3830\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 26s 1s/step - loss: 0.2166 - accuracy: 0.9078 - val_loss: 1.6418 - val_accuracy: 0.4894\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.2152 - accuracy: 0.9167 - val_loss: 3.9891 - val_accuracy: 0.3475\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.1876 - accuracy: 0.9202 - val_loss: 3.2855 - val_accuracy: 0.3475\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.1817 - accuracy: 0.9291 - val_loss: 2.3688 - val_accuracy: 0.4468\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.1595 - accuracy: 0.9326 - val_loss: 2.9449 - val_accuracy: 0.3262\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.1268 - accuracy: 0.9379 - val_loss: 1.9939 - val_accuracy: 0.4468\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 27s 1s/step - loss: 0.1939 - accuracy: 0.9255 - val_loss: 2.3517 - val_accuracy: 0.3617\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'Adam',metrics=['accuracy'])\n",
    "model_history=model.fit(x_train, y_train, batch_size=32, epochs = 20, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*******************Early Stopping*********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 - 28s - loss: 0.0463 - accuracy: 0.9811 - val_loss: 5.2914 - val_accuracy: 0.5319\n",
      "Epoch 2/200\n",
      "11/11 - 27s - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.3026 - val_accuracy: 0.8652\n",
      "Epoch 3/200\n",
      "11/11 - 28s - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.2283 - val_accuracy: 0.8936\n",
      "Epoch 4/200\n",
      "11/11 - 28s - loss: 0.0122 - accuracy: 0.9976 - val_loss: 0.1980 - val_accuracy: 0.9149\n",
      "Epoch 5/200\n",
      "11/11 - 28s - loss: 0.0189 - accuracy: 0.9905 - val_loss: 0.3893 - val_accuracy: 0.8936\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'Adam',metrics=['accuracy'])\n",
    "#model_history=model.fit(x_train, y_train, batch_size=32, epochs = 45, validation_data=(x_test, y_test))\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=200, \n",
    "    validation_split=0.25, \n",
    "    batch_size=40,      \n",
    "    verbose=2,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 - 20s - loss: 0.1118 - accuracy: 0.9534 - val_loss: 4.7271 - val_accuracy: 0.2832\n",
      "Epoch 2/200\n",
      "12/12 - 22s - loss: 0.0764 - accuracy: 0.9712 - val_loss: 1.8394 - val_accuracy: 0.6549\n",
      "Epoch 3/200\n",
      "12/12 - 21s - loss: 0.0606 - accuracy: 0.9778 - val_loss: 1.8003 - val_accuracy: 0.5841\n",
      "Epoch 4/200\n",
      "12/12 - 21s - loss: 0.0843 - accuracy: 0.9734 - val_loss: 1.9677 - val_accuracy: 0.7345\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'Adam',metrics=['accuracy'])\n",
    "#model_history=model.fit(x_train, y_train, batch_size=32, epochs = 45, validation_data=(x_test, y_test))\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=200, \n",
    "    validation_split=0.20, \n",
    "    batch_size=40,      \n",
    "    verbose=2,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 - 20s - loss: 0.2079 - accuracy: 0.9313 - val_loss: 2.1334 - val_accuracy: 0.4779\n",
      "Epoch 2/200\n",
      "12/12 - 21s - loss: 0.2649 - accuracy: 0.9157 - val_loss: 1.6774 - val_accuracy: 0.6195\n",
      "Epoch 3/200\n",
      "12/12 - 21s - loss: 0.2493 - accuracy: 0.9002 - val_loss: 0.4084 - val_accuracy: 0.7788\n",
      "Epoch 4/200\n",
      "12/12 - 21s - loss: 0.1341 - accuracy: 0.9468 - val_loss: 0.5487 - val_accuracy: 0.7965\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'Adam',metrics=['accuracy'])\n",
    "#model_history=model.fit(x_train, y_train, batch_size=32, epochs = 45, validation_data=(x_test, y_test))\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=200, \n",
    "    validation_split=0.20, \n",
    "    batch_size=40,      \n",
    "    verbose=2,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 - 18s - loss: 0.3043 - accuracy: 0.8869 - val_loss: 2.2756 - val_accuracy: 0.5133\n",
      "Epoch 2/200\n",
      "12/12 - 20s - loss: 0.1618 - accuracy: 0.9290 - val_loss: 0.6513 - val_accuracy: 0.8053\n",
      "Epoch 3/200\n",
      "12/12 - 21s - loss: 0.1680 - accuracy: 0.9401 - val_loss: 1.8121 - val_accuracy: 0.5929\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'Adam',metrics=['accuracy'])\n",
    "#model_history=model.fit(x_train, y_train, batch_size=32, epochs = 45, validation_data=(x_test, y_test))\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=200, \n",
    "    validation_split=0.20, \n",
    "    batch_size=40,      \n",
    "    verbose=2,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################Save Model##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nikita Majumder\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Nikita Majumder\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(\n",
    "    model.predict(x_test), reconstructed_model.predict(x_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 27s 2s/step - loss: 0.1949 - accuracy: 0.9202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e423c7d4c0>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is New Volume\n",
      " Volume Serial Number is F2BE-10BF\n",
      "\n",
      " Directory of D:\\Nikita Old Laptop\\TH Koln\\RP_NEW\\my_model\n",
      "\n",
      "31/10/2021  19:27    <DIR>          .\n",
      "31/10/2021  19:27    <DIR>          ..\n",
      "31/10/2021  19:27    <DIR>          assets\n",
      "31/10/2021  19:27           812.705 saved_model.pb\n",
      "31/10/2021  19:27    <DIR>          variables\n",
      "               1 File(s)        812.705 bytes\n",
      "               4 Dir(s)  15.021.133.824 bytes free\n"
     ]
    }
   ],
   "source": [
    "#The model architecture, and training configuration (including the optimizer, losses, and metrics) are stored in saved_model.pb. \n",
    "#The weights are saved in the variables/ directory.\n",
    "\n",
    "ls my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_122 (Conv1D)          (None, 431, 1024)         6144      \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 431, 1024)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 431, 1024)         4096      \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 431, 1024)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 215, 1024)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 215, 512)          2621952   \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 215, 512)          0         \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 215, 512)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 215, 512)          2048      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 107, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 107, 256)          655616    \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 107, 256)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 107, 256)          1024      \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 107, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 53, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 53, 128)           163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 53, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 53, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 53, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 26, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 26, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 26, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 26, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 26, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 13, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 13, 32)            10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 13, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 100)               41700     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 14)                1414      \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 14)                0         \n",
      "=================================================================\n",
      "Total params: 3,550,154\n",
      "Trainable params: 3,546,122\n",
      "Non-trainable params: 4,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 4s 240ms/step - loss: 0.5237 - accuracy: 0.8830\n"
     ]
    }
   ],
   "source": [
    "loss,acc = new_model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored Model, accuracy:88.30%\n"
     ]
    }
   ],
   "source": [
    "print('Restored Model, accuracy:{:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "import joblib\n",
    "app = Flask(__name__)\n",
    "loaded_model = joblib.load(my_model.h5)\n",
    "@app.route(\"/\")\n",
    "def root():\n",
    "    return render_template(\"index.html\")\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def make_prediction():\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        exp = request.form['exp']\n",
    "        X = [[float(exp)]]\n",
    "        [prediction] = loaded_model.predict(X)\n",
    "        salary = round(prediction, 2)\n",
    "    msg = \"Standard salary for provided experience of  \" + str(exp) + \" years, would be: ₹ \" + str(salary) + \"/-- \"\n",
    "\n",
    "    return render_template(\"index.html\", prediction_text= msg)\n",
    "if __name__ == '__main__':\n",
    "    app.run(  debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_model= model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fashionmnist_yamlmodel.yaml', 'w') as yaml_file:\n",
    "    yaml_file.write(yaml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fashionmnist_yamlmodel.yaml', 'r') as yaml_file:\n",
    "    yaml_savedModel=yaml_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
